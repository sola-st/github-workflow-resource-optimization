{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f9d3ac-f415-40bf-a65e-86961fa6b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from runs_collector.dataset import RunsDataSet\n",
    "from runs_analysis.resource_usage import get_tiers, calculate_costs\n",
    "from optimization.optimization_heuristics import (compute_wasted_schedule1, \n",
    "                                                  compute_wasted_schedule2, \n",
    "                                                  failed_jobs_prioritization, \n",
    "                                                  timeout_value_optimization, \n",
    "                                                  is_commit_inbetween)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f600504",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6dcb21-d013-40e5-81e6-9848de57ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from checkpoints\n",
      "Time taken to load the dataset: 67.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "data_set = RunsDataSet(None, None, from_checkpoint=True, checkpoint_dir=\"./\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken to load the dataset:\", round(end - start, 0), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e845190f-c388-44ba-abd5-31e91e0d141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = data_set.get_all_runs()\n",
    "all_jobs = data_set.get_all_jobs()\n",
    "all_jobs = data_set.get_all_jobs()\n",
    "all_runs = data_set.get_all_runs()\n",
    "jobs_runs_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\", \"start_ts\": \"min\"}).reset_index()\n",
    "runs_with_time = all_runs.merge(jobs_runs_time, left_on=\"id\", right_on=\"run_id\")\n",
    "repos_list_1, repos_list_2 = get_tiers(data_set)\n",
    "optimizations = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de50117-63ac-48dd-813e-052fcfcc4a36",
   "metadata": {},
   "source": [
    "## Wasted schedule afeter K failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa1d494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423240940\n",
      "0.14917972005498942\n",
      "1423240940\n",
      "0.0052491049055966585\n"
     ]
    }
   ],
   "source": [
    "wasted_schedule_paid = compute_wasted_schedule1(all_runs, all_jobs, repos_list_1)\n",
    "wasted_schedule_free = compute_wasted_schedule1(all_runs, all_jobs, repos_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb4a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"wasted_schedule\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\":wasted_schedule_paid[0]*100,\n",
    "        \"subset_runs\": wasted_schedule_paid[1]*100,\n",
    "        \"saved_time_all\": wasted_schedule_paid[2]*100,\n",
    "        \"saved_subset\": wasted_schedule_paid[3]*100,\n",
    "        \"saved_cost\": wasted_schedule_paid[4]\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\":wasted_schedule_free[0],\n",
    "        \"subset_runs\": wasted_schedule_free[1]*100,\n",
    "        \"saved_time_all\": wasted_schedule_free[2]*100,\n",
    "        \"saved_subset\": wasted_schedule_free[3]*100,\n",
    "        \"saved_cost\": wasted_schedule_free[4]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "789cb6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wasted_schedule': {'paid': {'all_runs': 4.51,\n",
       "   'subset_runs': 17.23,\n",
       "   'saved_time_all': 3.17,\n",
       "   'saved_subset': 21.279999999999998,\n",
       "   'saved_cost': 125.72},\n",
       "  'free': {'all_runs': 0.004,\n",
       "   'subset_runs': 1.0,\n",
       "   'saved_time_all': 0.03,\n",
       "   'saved_subset': 4.9,\n",
       "   'saved_cost': 1.55}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b370a-7e50-478f-918f-86944613aff2",
   "metadata": {},
   "source": [
    "## Wasted schedule during inactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2c0928-dba0-47cb-8ac0-84cdda6c9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repos = data_set.get_all_repositories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34f35ce-a337-48b1-a6cb-425ddc9ada3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commits history\n",
    "commits_dict = {}\n",
    "with open(\"commits_messages_by_repo.json\") as cmr:\n",
    "    collected_messages = json.load(cmr)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    if cm:\n",
    "        repo_name = cm[0][0]\n",
    "        if repo_name not in commits_dict:\n",
    "            commits_dict[repo_name] = [x[1] for x in cm]\n",
    "commits_dict_2 = {}\n",
    "with open(\"scraped_commits_messages_part2.json\") as cmr:\n",
    "    collected_messages = json.load(cmr)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    repo_name = cm[0]\n",
    "    if repo_name in commits_dict_2:\n",
    "        commits_dict_2[repo_name].append(cm[1])\n",
    "    else:\n",
    "        commits_dict_2[repo_name] = [cm[1]]\n",
    "\n",
    "commits_dict_3 = {}\n",
    "\n",
    "with open(\"collected_commits_messages_part3.json\") as cmm:\n",
    "    collected_messages = json.load(cmm)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    repo_name = cm[0]\n",
    "    if repo_name in commits_dict_3:\n",
    "        commits_dict_3[repo_name].append(cm[1])\n",
    "    else:\n",
    "        commits_dict_3[repo_name] = [cm[1]]\n",
    "\n",
    "commits_dict_3.update(commits_dict_2)\n",
    "commits_dict_3.update(commits_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359bead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423240940\n",
      "212318685\n",
      "1423240940\n",
      "7470741\n"
     ]
    }
   ],
   "source": [
    "all_runs_sub_1, total_waste_time, total_over_schedule, total_over_total, wasted_fails, saved_cost = compute_wasted_schedule2(\n",
    "                                                                                all_runs, all_jobs, all_repos, commits_dict_3, repos_list_1)\n",
    "all_runs_sub_2, total_waste_time2, total_over_schedule2, total_over_total2, wasted_fails2, saved_cost2 = compute_wasted_schedule2(\n",
    "                                                                                all_runs, all_jobs, all_repos, commits_dict_3, repos_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3ea41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"wasted_schedule_2\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\":len(wasted_fails)/all_runs_sub_1.shape[0]*100,\n",
    "        \"subset_runs\": len(wasted_fails)/all_runs_sub_1[all_runs_sub_1.event==\"schedule\"].shape[0]*100,\n",
    "        \"saved_time_all\": total_over_total,\n",
    "        \"saved_subset\": total_over_schedule,\n",
    "        \"saved_cost\": saved_cost\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\":len(wasted_fails2)/all_runs_sub_2.shape[0]*100,\n",
    "        \"subset_runs\": len(wasted_fails2)/all_runs_sub_2[all_runs_sub_2.event==\"schedule\"].shape[0]*100,\n",
    "        \"saved_time_all\": total_over_total2,\n",
    "        \"saved_subset\": total_over_schedule2,\n",
    "        \"saved_cost\": saved_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ac0394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wasted_schedule': {'paid': {'all_runs': 4.51,\n",
       "   'subset_runs': 17.23,\n",
       "   'saved_time_all': 3.17,\n",
       "   'saved_subset': 21.279999999999998,\n",
       "   'saved_cost': 125.72},\n",
       "  'free': {'all_runs': 0.004,\n",
       "   'subset_runs': 1.0,\n",
       "   'saved_time_all': 0.03,\n",
       "   'saved_subset': 4.9,\n",
       "   'saved_cost': 1.55}},\n",
       " 'wasted_schedule_2': {'paid': {'all_runs': 4.483177643393134,\n",
       "   'subset_runs': 17.11288579226899,\n",
       "   'saved_time_all': 0.0152,\n",
       "   'saved_subset': 0.1016,\n",
       "   'saved_cost': 99.78},\n",
       "  'free': {'all_runs': 0.5579242728169694,\n",
       "   'subset_runs': 1.3859651705406957,\n",
       "   'saved_time_all': 0.0004,\n",
       "   'saved_subset': 0.0753,\n",
       "   'saved_cost': 3.81}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f568653-d92d-441b-a1dc-ed73dc40db60",
   "metadata": {},
   "source": [
    "## Failed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ad1979-4e90-443a-8135-1bb17d533f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overall, time_over_impacted, impacted_runs, inlined_ids = failed_jobs_prioritization(data_set, repos_list_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a754d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_over_subset = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids)].run_id.to_list())].id.unique().shape[0]/all_runs_sub_1[all_runs_sub_1.conclusion==\"failure\"].shape[0]*100 + len(inlined_ids) / all_runs_sub_1[all_runs_sub_1.conclusion==\"failure\"].shape[0] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ba4d6-6de0-47cb-b806-20551da3b96a",
   "metadata": {},
   "source": [
    "### Delta cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e118501-5b97-40bd-ae02-242494f4f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_runs = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids)].run_id.to_list())]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "delta_cost = calculate_costs(all_jobs[all_jobs.id.isin(inlined_ids)].up_time.sum() / 60 / years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f8d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overall2, time_over_impacted2, impacted_runs2, inlined_ids2 = failed_jobs_prioritization(data_set, repos_list_2)\n",
    "impact_over_subset2 = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids2)].run_id.to_list())].id.unique().shape[0]/all_runs_sub_2[all_runs_sub_2.conclusion==\"failure\"].shape[0]*100\n",
    "sub_runs2 = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids2)].run_id.to_list())]\n",
    "min_max_start_ts2 = sub_runs2.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts2 = 0\n",
    "for i, row in min_max_start_ts2.iterrows():\n",
    "    total_start_ts2 += row[\"max\"] - row[\"min\"]\n",
    "years2 = total_start_ts2/(12*30*24*3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab754531",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_cost2 = calculate_costs(all_jobs[all_jobs.id.isin(inlined_ids2)].up_time.sum() / 60 / years2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16f0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"failed_jobs\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\": impacted_runs,\n",
    "        \"subset_runs\": impact_over_subset,\n",
    "        \"saved_time_all\": time_overall*100,\n",
    "        \"saved_subset\": time_over_impacted*100,\n",
    "        \"saved_cost\": delta_cost\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\":impacted_runs2,\n",
    "        \"subset_runs\": impact_over_subset2,\n",
    "        \"saved_time_all\": time_overall2*100,\n",
    "        \"saved_subset\": time_over_impacted2*100,\n",
    "        \"saved_cost\": delta_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96f17a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wasted_schedule': {'paid': {'all_runs': 4.51,\n",
       "   'subset_runs': 17.23,\n",
       "   'saved_time_all': 3.17,\n",
       "   'saved_subset': 21.279999999999998,\n",
       "   'saved_cost': 125.72},\n",
       "  'free': {'all_runs': 0.004,\n",
       "   'subset_runs': 1.0,\n",
       "   'saved_time_all': 0.03,\n",
       "   'saved_subset': 4.9,\n",
       "   'saved_cost': 1.55}},\n",
       " 'wasted_schedule_2': {'paid': {'all_runs': 4.483177643393134,\n",
       "   'subset_runs': 17.11288579226899,\n",
       "   'saved_time_all': 0.0152,\n",
       "   'saved_subset': 0.1016,\n",
       "   'saved_cost': 99.78},\n",
       "  'free': {'all_runs': 0.5579242728169694,\n",
       "   'subset_runs': 1.3859651705406957,\n",
       "   'saved_time_all': 0.0004,\n",
       "   'saved_subset': 0.0753,\n",
       "   'saved_cost': 3.81}},\n",
       " 'failed_jobs': {'paid': {'all_runs': 1.0311084492222633,\n",
       "   'subset_runs': 29.516355140186917,\n",
       "   'saved_time_all': 108.02801246006877,\n",
       "   'saved_subset': 3161.909848384515,\n",
       "   'saved_cost': 17.89},\n",
       "  'free': {'all_runs': 0.777775473257857,\n",
       "   'subset_runs': 7.739938080495357,\n",
       "   'saved_time_all': 2.7742807904331364,\n",
       "   'saved_subset': 4527.272768966877,\n",
       "   'saved_cost': 0.77}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3889b-282e-4af6-b964-620a8c34a7f5",
   "metadata": {},
   "source": [
    "## Timeout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9148363-6a0b-4451-9b1b-9515023e3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_repos_list = repos_list_1\n",
    "saved_time, impacted_runs = timeout_value_optimization(data_set, sub_repos_list)\n",
    "all_runs = data_set.get_all_runs()\n",
    "impacted_runs1 = len(impacted_runs) / all_runs[all_runs.repo_id.isin(sub_repos_list)].shape[0]*100\n",
    "saved_time1 = sum([s for s in saved_time if not np.isnan(s)]) / all_jobs[all_jobs.run_id.isin(all_runs[all_runs.repo_id.isin(sub_repos_list)].id.to_list())].up_time.sum()*100\n",
    "sub_runs = all_runs[all_runs.id.isin(impacted_runs)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost1 = calculate_costs(sum([s for s in saved_time if not np.isnan(s)]) / 60 / years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209ffb83-f3d7-4530-985e-9f65e369b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_repos_list = repos_list_2\n",
    "saved_time, impacted_runs = timeout_value_optimization(data_set, sub_repos_list)\n",
    "all_runs = data_set.get_all_runs()\n",
    "impacted_runs2 = len(impacted_runs) / all_runs[all_runs.repo_id.isin(sub_repos_list)].shape[0]*100\n",
    "saved_time2 = sum([s for s in saved_time if not np.isnan(s)]) / all_jobs[all_jobs.run_id.isin(all_runs[all_runs.repo_id.isin(sub_repos_list)].id.to_list())].up_time.sum()*100\n",
    "sub_runs = all_runs[all_runs.id.isin(impacted_runs)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost2 = calculate_costs(sum([s for s in saved_time if not np.isnan(s)]) / 60 / years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8cd96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"vm_timeout\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\": impacted_runs1,\n",
    "        \"saved_time_all\": saved_time1,\n",
    "        \"saved_cost\": saved_cost1\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\": impacted_runs2,\n",
    "        \"saved_time_all\": saved_time2,\n",
    "        \"saved_cost\": saved_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4762cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {\n",
    "    \"wasted_schedule\": \"Deactivate after k failures\",\n",
    "    \"wasted_schedule_2\": \"Deactivate during inactivity\",\n",
    "    \"failed_jobs\": \"Run failed jobs first\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d783d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization heuristic                   Impacted runs %                          Time saving %                            Annual cost delta $                     \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Deactivate scheduled workflows           4.5% (0.0%) of all runs                  3.2% (0.0%) of all runs time             -125.72 (-1.55)                         \n",
      "after k consecutive failures (k=3)       17.2% (1.0%) of scheduled runs           21.3% (4.9%) of scheduled runs                                                   \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Deactivate scheduled workflows           4.5% (0.6%) of all runs                  0.0% (0.0%) of all runs time             -99.78 (-3.81)                          \n",
      "during repository inactivity             17.1% (1.4%) of scheduled runs           0.1% (0.1%) of scheduled runs                                                    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Run previously failed jobs               1.0% (0.8%) of all runs                  1.1% (0.0%) of all runs time             -17.89 (-0.77)                          \n",
      "first                                    29.5% (7.7%) of failed runs              31.6% (45.3%) of failed runs                                                     \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Project-specific timeouts                0.5% (0.0%) of all runs                  3.5% (2.2%) of all runs time             -173.71 (-47.49)                        \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "        \"Optimization heuristic\",\n",
    "        \"Impacted runs %\",\n",
    "        \"Time saving %\",\n",
    "        \"Annual cost delta $\"\n",
    "         ))\n",
    "print(\"-\"*40*4)\n",
    "optim = \"wasted_schedule\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Deactivate scheduled workflows\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"], 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"after k consecutive failures (k=3)\",\n",
    "    str(round(o[\"paid\"][\"subset_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"subset_runs\"], 1)) + \"%) of scheduled runs\",\n",
    "    str(round(o[\"paid\"][\"saved_subset\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_subset\"], 1)) + \"%) of scheduled runs\",\n",
    "    \"\"))\n",
    "print(\"-\"*40*4)\n",
    "\n",
    "optim = \"wasted_schedule_2\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Deactivate scheduled workflows\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"], 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))  \n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"during repository inactivity\",\n",
    "    str(round(o[\"paid\"][\"subset_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"subset_runs\"], 1)) + \"%) of scheduled runs\",\n",
    "    str(round(o[\"paid\"][\"saved_subset\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_subset\"], 1)) + \"%) of scheduled runs\",\n",
    "    \"\"))\n",
    "print(\"-\"*40*4)\n",
    "\n",
    "optim = \"failed_jobs\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Run previously failed jobs\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"]/100, 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"]/100, 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"first\",\n",
    "    str(round(o[\"paid\"][\"subset_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"subset_runs\"], 1)) + \"%) of failed runs\",\n",
    "    str(round(o[\"paid\"][\"saved_subset\"]/100, 1)) + \"% (\" + str(round(o[\"free\"][\"saved_subset\"]/100, 1)) + \"%) of failed runs\",\n",
    "    \"\"))\n",
    "print(\"-\"*40*4)\n",
    "\n",
    "optim = \"vm_timeout\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Project-specific timeouts\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"], 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"-\"*40*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495685c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
