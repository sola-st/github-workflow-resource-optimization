{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f9d3ac-f415-40bf-a65e-86961fa6b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from runs_collector.dataset import RunsDataSet\n",
    "from runs_analysis.resource_usage import get_tiers\n",
    "from optimization.optimization_heuristics import get_wasted_schedule_1, get_wasted_schedule_2, failed_jobs_prioritization, timeout_value_optimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6dcb21-d013-40e5-81e6-9848de57ee68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from checkpoints\n",
      "Time taken to load the dataset: 78.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "data_set = RunsDataSet(None, None, from_checkpoint=True, checkpoint_dir=\"./\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken to load the dataset:\", round(end - start, 0), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e845190f-c388-44ba-abd5-31e91e0d141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs = data_set.get_all_runs()\n",
    "\n",
    "all_runs.repo_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6a3419-42e9-41d8-af45-4fea5b0289c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs = data_set.get_all_jobs()\n",
    "all_jobs = data_set.get_all_jobs()\n",
    "all_runs = data_set.get_all_runs()\n",
    "jobs_runs_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\", \"start_ts\": \"min\"}).reset_index()\n",
    "runs_with_time = all_runs.merge(jobs_runs_time, left_on=\"id\", right_on=\"run_id\")\n",
    "repos_list_1, repos_list_2 = get_tiers(data_set)\n",
    "optimizations = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de50117-63ac-48dd-813e-052fcfcc4a36",
   "metadata": {},
   "source": [
    "## Wasted schedule afeter K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "284e5b97-2996-48f5-bbcd-6326fc378fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423240940\n",
      "0.14917972005498942\n"
     ]
    }
   ],
   "source": [
    "all_runs_sub_1 = all_runs[all_runs.repo_id.isin(repos_list_1)]\n",
    "total_waste, waste_over_total_schedule, total_over_total, impacted_runs_schedule, impacted_runs_all, opt_repos = get_wasted_schedule_1(all_runs_sub_1, all_jobs, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8b093-6f1f-432f-b2fe-f4201d863956",
   "metadata": {},
   "source": [
    "### Impacted runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f118197-bba7-4b70-a042-94a1a20f7b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among all runs: 0.0451\n",
      "Among scheduled: 0.1723\n"
     ]
    }
   ],
   "source": [
    "print(\"Among all runs:\", impacted_runs_all)\n",
    "print(\"Among scheduled:\", impacted_runs_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263f806d-0775-406f-bc24-d15bfc4aeb68",
   "metadata": {},
   "source": [
    "### Saved time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf327d53-dbb4-4c99-ab41-867457412e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved time over all runs: 0.0317\n",
      "Saved time over all schedule: 0.2128\n"
     ]
    }
   ],
   "source": [
    "print(\"Saved time over all runs:\", total_over_total)\n",
    "print(\"Saved time over all schedule:\", waste_over_total_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294d9d5-3e85-43d0-b426-b1fa35c91ab8",
   "metadata": {},
   "source": [
    "### Saved cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16527cdd-c327-45be-b310-6715123d6e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved cost yearly per repo: 125.71513276249759\n"
     ]
    }
   ],
   "source": [
    "all_runs[\"start_ts\"] = all_runs.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "sub_runs = all_runs[all_runs.repo_id.isin(opt_repos)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost = total_waste / 60 / years * 0.008 * 1.52\n",
    "print(\"saved cost yearly per repo:\", saved_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45549cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423240940\n",
      "0.0052491049055966585\n"
     ]
    }
   ],
   "source": [
    "all_runs_sub_2 = all_runs[all_runs.repo_id.isin(repos_list_2)]\n",
    "total_waste2, waste_over_total_schedule2, total_over_total2, impacted_runs_schedule2, impacted_runs_all2, opt_repos2 = get_wasted_schedule_1(\n",
    "    all_runs_sub_2, all_jobs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c05f88c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved cost yearly per repo: 1.5510287232659694\n"
     ]
    }
   ],
   "source": [
    "all_runs[\"start_ts\"] = all_runs.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "sub_runs = all_runs[all_runs.repo_id.isin(opt_repos2)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost2 = total_waste2 / 60 / years * 0.008 * 1.52\n",
    "print(\"saved cost yearly per repo:\", saved_cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb4a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"wasted_schedule\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\":impacted_runs_all,\n",
    "        \"subset_runs\": impacted_runs_schedule,\n",
    "        \"saved_time_all\": total_over_total,\n",
    "        \"saved_subset\": waste_over_total_schedule,\n",
    "        \"saved_cost\": saved_cost\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\":impacted_runs_all2,\n",
    "        \"subset_runs\": impacted_runs_schedule2,\n",
    "        \"saved_time_all\": total_over_total2,\n",
    "        \"saved_subset\": waste_over_total_schedule2,\n",
    "        \"saved_cost\": saved_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b370a-7e50-478f-918f-86944613aff2",
   "metadata": {},
   "source": [
    "## Wasted schedule during inactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2c0928-dba0-47cb-8ac0-84cdda6c9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repos = data_set.get_all_repositories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd45e3b-d526-4180-81e1-3dc60f3513ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_commit_inbetween(ts, previous_ts, repo_name, commits):\n",
    "    if repo_name in commits:\n",
    "        for cm_ts in commits[repo_name]:\n",
    "            if cm_ts < ts and previous_ts < cm_ts:\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        return False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d34f35ce-a337-48b1-a6cb-425ddc9ada3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict = {}\n",
    "with open(\"commits_messages_by_repo.json\") as cmr:\n",
    "    collected_messages = json.load(cmr)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    if cm:\n",
    "        repo_name = cm[0][0]\n",
    "        if repo_name not in commits_dict:\n",
    "            commits_dict[repo_name] = [x[1] for x in cm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b896ca-dfaa-4843-a14f-0ddb92196d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict_2 = {}\n",
    "with open(\"scraped_commits_messages_part2.json\") as cmr:\n",
    "    collected_messages = json.load(cmr)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    repo_name = cm[0]\n",
    "    if repo_name in commits_dict_2:\n",
    "        commits_dict_2[repo_name].append(cm[1])\n",
    "    else:\n",
    "        commits_dict_2[repo_name] = [cm[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b31b585-24e6-47da-ab1f-02e86a32d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict_3 = {}\n",
    "\n",
    "with open(\"collected_commits_messages_part3.json\") as cmm:\n",
    "    collected_messages = json.load(cmm)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    repo_name = cm[0]\n",
    "    if repo_name in commits_dict_3:\n",
    "        commits_dict_3[repo_name].append(cm[1])\n",
    "    else:\n",
    "        commits_dict_3[repo_name] = [cm[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c001ce-afb8-49b6-b8cd-c85d9eb3f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict_3.update(commits_dict_2)\n",
    "commits_dict_3.update(commits_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44619fe7-dd2e-4655-b629-e37f62ff5b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423240940\n",
      "212318685\n"
     ]
    }
   ],
   "source": [
    "all_runs_sub_1 = all_runs[all_runs.repo_id.isin(repos_list_1)]\n",
    "total_waste_time, total_over_schedule, total_over_total, wasted_fails = get_wasted_schedule_2(all_runs_sub_1, all_jobs, all_repos, commits_dict_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373233c-d561-4f06-813d-3d4ac3d968b5",
   "metadata": {},
   "source": [
    "### Impacted runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6d315e8-b43b-4a2c-b081-952c15174eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over all runs: 4.199503136716852\n",
      "Over all scheduled: 16.03006244216518\n"
     ]
    }
   ],
   "source": [
    "print(\"Over all runs:\", len(wasted_fails)/all_runs_sub_1.shape[0]*100)\n",
    "print(\"Over all scheduled:\", len(wasted_fails)/all_runs_sub_1[all_runs_sub_1.event==\"schedule\"].shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9788d8-36f0-47d0-817b-eba2201c5fb0",
   "metadata": {},
   "source": [
    "### Saved time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceb534cb-7ef0-418e-b768-d8a03f7ce237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved time over all runs: 0.0016\n",
      "Saved time over all schedule: 0.0107\n"
     ]
    }
   ],
   "source": [
    "print(\"Saved time over all runs:\", total_over_total)\n",
    "print(\"Saved time over all schedule:\", total_over_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effece04-e516-4f53-bb76-998c329e9dc1",
   "metadata": {},
   "source": [
    "### Cost delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "481b4cd7-1f76-4c83-9d0e-547a024e71c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_runs = all_runs[all_runs.id.isin(wasted_fails)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost = total_waste_time / 60 / years * 0.008 * 1.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "257ec7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423240940\n",
      "7470741\n"
     ]
    }
   ],
   "source": [
    "all_runs_sub_2 = all_runs[all_runs.repo_id.isin(repos_list_2)]\n",
    "total_waste_time2, total_over_schedule2, total_over_total2, wasted_fails2 = get_wasted_schedule_2(all_runs_sub_2, all_jobs, all_repos, commits_dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aadd1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_runs2 = all_runs[all_runs.id.isin(wasted_fails2)]\n",
    "min_max_start_ts2 = sub_runs2.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts2 = 0\n",
    "for i, row in min_max_start_ts2.iterrows():\n",
    "    total_start_ts2 += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts2/(12*30*24*3600)\n",
    "saved_cost2 = total_waste_time2 / 60 / years * 0.008 * 1.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ea41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"wasted_schedule_2\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\":len(wasted_fails)/all_runs_sub_1.shape[0]*100,\n",
    "        \"subset_runs\": len(wasted_fails)/all_runs_sub_1[all_runs_sub_1.event==\"schedule\"].shape[0]*100,\n",
    "        \"saved_time_all\": total_over_total,\n",
    "        \"saved_subset\": waste_over_total_schedule,\n",
    "        \"saved_cost\": saved_cost\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\":len(wasted_fails2)/all_runs_sub_2.shape[0]*100,\n",
    "        \"subset_runs\": len(wasted_fails2)/all_runs_sub_2[all_runs_sub_2.event==\"schedule\"].shape[0]*100,\n",
    "        \"saved_time_all\": total_over_total2,\n",
    "        \"saved_subset\": waste_over_total_schedule2,\n",
    "        \"saved_cost\": saved_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f568653-d92d-441b-a1dc-ed73dc40db60",
   "metadata": {},
   "source": [
    "## Failed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5ad1979-4e90-443a-8135-1bb17d533f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overall, time_over_impacted, impacted_runs, inlined_ids = failed_jobs_prioritization(data_set, repos_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba48e1-dcc7-4d1e-8a74-2926d0bab4c2",
   "metadata": {},
   "source": [
    "### Saved time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "008ec6cc-41f0-43aa-abbe-b9b2c105b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time over all: 1.0826092453467506\n",
      "Time over impacted: 31.818142113442928\n"
     ]
    }
   ],
   "source": [
    "print(\"Time over all:\", time_overall)\n",
    "print(\"Time over impacted:\", time_over_impacted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf7fc8-2977-45da-bde9-c6d10113788a",
   "metadata": {},
   "source": [
    "### Impacted runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2741517-bb63-481a-8eb6-cd28eeda7da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0299880113143856"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impacted_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "050acda1-83f4-4c4a-9d7a-2c7dfe8bedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_over_subset = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids)].run_id.to_list())].id.unique().shape[0]/all_runs_sub_1[all_runs_sub_1.conclusion==\"failure\"].shape[0]*100 + len(inlined_ids) / all_runs_sub_1[all_runs_sub_1.conclusion==\"failure\"].shape[0] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ba4d6-6de0-47cb-b806-20551da3b96a",
   "metadata": {},
   "source": [
    "### Delta cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e118501-5b97-40bd-ae02-242494f4f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_runs = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids)].run_id.to_list())]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "delta_cost = all_jobs[all_jobs.id.isin(inlined_ids)].up_time.sum() / 60 / years * 0.008 * 1.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3f8d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overall2, time_over_impacted2, impacted_runs2, inlined_ids2 = failed_jobs_prioritization(data_set, repos_list_2)\n",
    "impact_over_subset2 = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids2)].run_id.to_list())].id.unique().shape[0]/all_runs_sub_2[all_runs_sub_2.conclusion==\"failure\"].shape[0]*100\n",
    "sub_runs2 = all_runs[all_runs.id.isin(all_jobs[all_jobs.id.isin(inlined_ids2)].run_id.to_list())]\n",
    "min_max_start_ts2 = sub_runs2.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts2 = 0\n",
    "for i, row in min_max_start_ts2.iterrows():\n",
    "    total_start_ts2 += row[\"max\"] - row[\"min\"]\n",
    "years2 = total_start_ts2/(12*30*24*3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab754531",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_cost2 = all_jobs[all_jobs.id.isin(inlined_ids2)].up_time.sum() / 60 / years2 * 0.008 * 1.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e16f0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"failed_jobs\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\": impacted_runs,\n",
    "        \"subset_runs\": impact_over_subset,\n",
    "        \"saved_time_all\": time_overall,\n",
    "        \"saved_subset\": time_over_impacted,\n",
    "        \"saved_cost\": delta_cost\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\":impacted_runs2,\n",
    "        \"subset_runs\": impact_over_subset2,\n",
    "        \"saved_time_all\": time_overall2,\n",
    "        \"saved_subset\": time_over_impacted2,\n",
    "        \"saved_cost\": delta_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3889b-282e-4af6-b964-620a8c34a7f5",
   "metadata": {},
   "source": [
    "## Timeout value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be7a0ee5-ee67-4e2e-a00f-1214e8e0a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout_value_optimization(data_set, repos_list):\n",
    "    all_runs = data_set.get_all_runs()\n",
    "    all_runs = all_runs[all_runs.repo_id.isin(repos_list)]\n",
    "    all_jobs = data_set.get_all_jobs()\n",
    "    runs_total_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\"}).reset_index()\n",
    "    all_runs_time = all_runs.merge(runs_total_time, left_on=\"id\", right_on=\"run_id\")\n",
    "    all_runs_time[\"start_ts\"] = all_runs_time.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "    saved_time = []\n",
    "    total_impact_time = []\n",
    "    impacted_runs = []\n",
    "    window = 10\n",
    "    fraction = 0.1\n",
    "    workflows_ids = all_runs.workflow_id.unique().tolist()\n",
    "    for workflow_id in workflows_ids:\n",
    "        workflow_runs = all_runs_time[all_runs_time.workflow_id==workflow_id].sort_values(\"run_number\")\n",
    "        if workflow_runs.shape[0]==0:\n",
    "            continue\n",
    "        else:\n",
    "            workflow_jobs = all_jobs[all_jobs.run_id.isin(workflow_runs.id)]\n",
    "            jobs_names = workflow_jobs.name.unique().tolist()\n",
    "            for job_name in jobs_names:\n",
    "                jobs = workflow_jobs[workflow_jobs.name==job_name]\n",
    "                max_time = jobs[jobs.up_time<=21541].up_time.max()\n",
    "                target_jobs = jobs[jobs.up_time>21541]\n",
    "                if target_jobs.shape[0]!=0:\n",
    "                    saved_time.append(target_jobs.up_time.sum() - target_jobs.shape[0] * max_time*1.1)\n",
    "                    impacted_runs.extend(target_jobs.run_id.to_list())\n",
    "                    \n",
    "    return saved_time, impacted_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c9148363-6a0b-4451-9b1b-9515023e3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_repos_list = repos_list_1\n",
    "saved_time, impacted_runs = timeout_value_optimization(data_set, sub_repos_list)\n",
    "all_runs = data_set.get_all_runs()\n",
    "impacted_runs1 = len(impacted_runs) / all_runs[all_runs.repo_id.isin(sub_repos_list)].shape[0]*100\n",
    "saved_time1 = sum([s for s in saved_time if not np.isnan(s)]) / all_jobs[all_jobs.run_id.isin(all_runs[all_runs.repo_id.isin(sub_repos_list)].id.to_list())].up_time.sum()*100\n",
    "sub_runs = all_runs[all_runs.id.isin(impacted_runs)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost1 = sum([s for s in saved_time if not np.isnan(s)]) / 60 / years * 0.008 * 1.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "209ffb83-f3d7-4530-985e-9f65e369b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_repos_list = repos_list_2\n",
    "saved_time, impacted_runs = timeout_value_optimization(data_set, sub_repos_list)\n",
    "all_runs = data_set.get_all_runs()\n",
    "impacted_runs2 = len(impacted_runs) / all_runs[all_runs.repo_id.isin(sub_repos_list)].shape[0]*100\n",
    "saved_time2 = sum([s for s in saved_time if not np.isnan(s)]) / all_jobs[all_jobs.run_id.isin(all_runs[all_runs.repo_id.isin(sub_repos_list)].id.to_list())].up_time.sum()*100\n",
    "sub_runs = all_runs[all_runs.id.isin(impacted_runs)]\n",
    "min_max_start_ts = sub_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in min_max_start_ts.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "years = total_start_ts/(12*30*24*3600)\n",
    "saved_cost2 = sum([s for s in saved_time if not np.isnan(s)]) / 60 / years * 0.008 * 1.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8cd96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"vm_timeout\"] = {\n",
    "    \"paid\":{\n",
    "        \"all_runs\": impacted_runs1,\n",
    "        \"saved_time_all\": saved_time1,\n",
    "        \"saved_cost\": saved_cost1\n",
    "    },\n",
    "    \"free\":{\n",
    "        \"all_runs\": impacted_runs2,\n",
    "        \"saved_time_all\": saved_time2,\n",
    "        \"saved_cost\": saved_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4762cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {\n",
    "    \"wasted_schedule\": \"Deactivate after k failures\",\n",
    "    \"wasted_schedule_2\": \"Deactivate during inactivity\",\n",
    "    \"failed_jobs\": \"Run failed jobs first\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d783d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization heuristic                   Impacted runs %                          Time saving %                            Annual cost delta $                     \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Deactivate scheduled workflows           4.5% (0.4%) of all runs                  3.2% (0.0%) of all runs time             -125.72 (-1.55)                         \n",
      "after k consecutive failures (k=3)       17.2% (1.0%) of scheduled runs           21.3% (4.9%) of scheduled runs                                                   \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Deactivate scheduled workflows           4.2% (0.2%) of all runs                  0.0% (0.0%) of all runs time             -68.97 (-7.97)                          \n",
      "during repository inactivity             16.0% (0.5%) of scheduled runs           0.2% (0.0%) of scheduled runs                                                    \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Run previously failed jobs               1.0% (0.8%) of all runs                  1.1% (0.0%) of all runs time             -17.89 (-0.77)                          \n",
      "first                                    29.5% (7.7%) of failed runs              31.6% (45.3%) of failed runs                                                     \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Project-specific timeouts                0.5% (0.0%) of all runs                  3.5% (2.2%) of all runs time             -173.71 (-47.49)                        \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "        \"Optimization heuristic\",\n",
    "        \"Impacted runs %\",\n",
    "        \"Time saving %\",\n",
    "        \"Annual cost delta $\"\n",
    "         ))\n",
    "print(\"-\"*40*4)\n",
    "optim = \"wasted_schedule\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Deactivate scheduled workflows\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"]*100, 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"]*100, 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"]*100, 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"]*100, 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"after k consecutive failures (k=3)\",\n",
    "    str(round(o[\"paid\"][\"subset_runs\"]*100, 1)) + \"% (\" + str(round(o[\"free\"][\"subset_runs\"]*100, 1)) + \"%) of scheduled runs\",\n",
    "    str(round(o[\"paid\"][\"saved_subset\"]*100, 1)) + \"% (\" + str(round(o[\"free\"][\"saved_subset\"]*100, 1)) + \"%) of scheduled runs\",\n",
    "    \"\"))\n",
    "print(\"-\"*40*4)\n",
    "\n",
    "optim = \"wasted_schedule_2\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Deactivate scheduled workflows\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"], 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"during repository inactivity\",\n",
    "    str(round(o[\"paid\"][\"subset_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"subset_runs\"], 1)) + \"%) of scheduled runs\",\n",
    "    str(round(o[\"paid\"][\"saved_subset\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_subset\"], 1)) + \"%) of scheduled runs\",\n",
    "    \"\"))\n",
    "print(\"-\"*40*4)\n",
    "\n",
    "optim = \"failed_jobs\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Run previously failed jobs\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"], 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"first\",\n",
    "    str(round(o[\"paid\"][\"subset_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"subset_runs\"], 1)) + \"%) of failed runs\",\n",
    "    str(round(o[\"paid\"][\"saved_subset\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_subset\"], 1)) + \"%) of failed runs\",\n",
    "    \"\"))\n",
    "print(\"-\"*40*4)\n",
    "\n",
    "optim = \"vm_timeout\"\n",
    "o = optimizations[optim]\n",
    "print(\"{:<40} {:<40} {:<40} {:<40}\".format(\n",
    "    \"Project-specific timeouts\",\n",
    "    str(round(o[\"paid\"][\"all_runs\"], 1)) + \"% (\" + str(round(o[\"free\"][\"all_runs\"], 1)) + \"%) of all runs\",\n",
    "    str(round(o[\"paid\"][\"saved_time_all\"], 1)) + \"% (\" + str(round(o[\"free\"][\"saved_time_all\"], 1)) + \"%) of all runs time\",\n",
    "    \"-\" + str(round(o[\"paid\"][\"saved_cost\"], 2)) + \" (-\" + str(round(o[\"free\"][\"saved_cost\"], 2)) + \")\"\n",
    "        ))\n",
    "print(\"-\"*40*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706b661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
