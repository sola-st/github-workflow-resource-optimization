{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d024db-4023-4bc9-a88b-c95ef880e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from runs_collector.dataset import RunsDataSet\n",
    "from runs_analysis.resource_usage import get_tiers\n",
    "from optimization.github_optimization import (get_optimization_usage, \n",
    "                                              get_optimization_ts, \n",
    "                                              cancel_in_progress_impact, \n",
    "                                              calc_skip_impact,\n",
    "                                              calc_cache_impact,\n",
    "                                              get_cache_ts,\n",
    "                                              calc_cancel_in_progress_impact,\n",
    "                                              get_optimization_usage_avm,\n",
    "                                              get_optimization_ts_avm)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6eb2e-5178-407c-88da-723a48953e6c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158e2098-f45e-47b8-b76a-ba3f304f45c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from checkpoints\n",
      "Time taken to load the dataset: 59.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "os.chdir(\"/workdir\")\n",
    "data_set = RunsDataSet(None, None, from_checkpoint=True, checkpoint_dir=\"./\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken to load the dataset:\", round(end - start, 0), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4a5897-bab3-4f42-87c3-bda3f50c651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs = data_set.get_all_jobs()\n",
    "all_runs = data_set.get_all_runs()\n",
    "jobs_runs_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\", \"start_ts\": \"min\"}).reset_index()\n",
    "runs_with_time = all_runs.merge(jobs_runs_time, left_on=\"id\", right_on=\"run_id\")\n",
    "repos_list_1, repos_list_2 = get_tiers(data_set)\n",
    "all_repos = data_set.get_all_repositories()\n",
    "# paid tier repos\n",
    "list_1_names = all_repos[all_repos.id.isin(repos_list_1)].full_name.to_list()\n",
    "# free tier repos\n",
    "list_2_names = all_repos[all_repos.id.isin(repos_list_2)].full_name.to_list()\n",
    "optimizations = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4063f12-0df4-4dcc-9c20-fadbdfd90d3b",
   "metadata": {},
   "source": [
    "## cancel in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a4ba82-2e16-4ea2-843d-9dc6e8788c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_commits = []\n",
    "with open(\"collected_commits_save_poins.json\") as ccs:\n",
    "    collected_commits += json.load(ccs)\n",
    "with open(\"collected_commits_save_point_part2.json\") as ccsp:\n",
    "    collected_commits += json.load(ccsp)\n",
    "#with open(\"collected_commits_save_point_part3.json\") as ccsp:\n",
    "#    collected_commits += json.load(ccsp)\n",
    "with open(\"collected_commits_save_point_part4.json\") as ccsp:\n",
    "    collected_commits += json.load(ccsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3894ae-571a-46a2-adc7-b056776f3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel_usage = get_optimization_usage(collected_commits, optimization=\"cancel-in-progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b060b-fc55-40e6-b7bf-a8b8bcade2a0",
   "metadata": {},
   "source": [
    "### Impacted repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9482a4cc-21b6-43d6-93b6-d9b835e1f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_with = set([x[0] for x in cancel_usage[\"created_with_optimization\"]])\n",
    "added = set([x[0] for x in cancel_usage[\"optimization_removed\"]])\n",
    "removed = set([x[0] for x in cancel_usage[\"optimization_added\"]])\n",
    "cip_adoption_1 = len((created_with|\n",
    "    added|\n",
    "    removed) & set(list_1_names))/len(list_1_names)*100\n",
    "cip_adoption_2 = len((created_with|\n",
    "    added|\n",
    "    removed) & set(list_2_names))/len(list_2_names)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d64ed98-181b-46ba-b24d-9d12fa668dfc",
   "metadata": {},
   "source": [
    "### Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f931d35-0b3e-4539-a15e-562ca521e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_runs1, possible_ids1, optimized_ids1 = cancel_in_progress_impact(data_set, repos_list_1, collected_commits)\n",
    "optimized_runs2, possible_ids2, optimized_ids2 = cancel_in_progress_impact(data_set, repos_list_2, collected_commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157b7a9f-24b0-4280-8cfc-2bfd573ac462",
   "metadata": {},
   "outputs": [],
   "source": [
    "cip_time2, cip_runs2, cip_cost2 = calc_cancel_in_progress_impact(data_set, possible_ids2, optimized_ids2, optimized_runs2)\n",
    "cip_time1, cip_runs1, cip_cost1 = calc_cancel_in_progress_impact(data_set, possible_ids1, optimized_ids1, optimized_runs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36097367",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"cancel_in_progress\"]={\n",
    "    \"paid\":{\n",
    "        \"adoption\": cip_adoption_1,\n",
    "        \"impacted_runs\": cip_runs1,\n",
    "        \"time_impact\": cip_time1,\n",
    "        \"cost_impact\": cip_cost1\n",
    "        },\n",
    "    \"free\":{\n",
    "        \"adoption\": cip_adoption_2,\n",
    "        \"impacted_runs\": cip_runs2,\n",
    "        \"time_impact\": cip_time2,\n",
    "        \"cost_impact\": cip_cost2\n",
    "        } \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d65ed1-e8f8-4ef0-9f71-db25cdcdfd36",
   "metadata": {},
   "source": [
    "## skip workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c04584a2-3f83-4d84-8f09-653fb9b57cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict = {}\n",
    "with open(\"commits_messages_by_repo.json\") as cmr:\n",
    "    collected_messages = json.load(cmr)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    if cm:\n",
    "        repo_name = cm[0][0]\n",
    "        if repo_name not in commits_dict:\n",
    "            commits_dict[repo_name] = [x[2] for x in cm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc86fb58-f7f3-40fe-aeb6-770df12222eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict_2 = {}\n",
    "with open(\"scraped_commits_messages_part2.json\") as cmr:\n",
    "    collected_messages = json.load(cmr)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    repo_name = cm[0]\n",
    "    if repo_name in commits_dict_2:\n",
    "        commits_dict_2[repo_name].append(cm[2])\n",
    "    else:\n",
    "        commits_dict_2[repo_name] = [cm[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b63e197-da65-45f3-8eb8-4f59dd558fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict_3 = {}\n",
    "\n",
    "with open(\"collected_commits_messages_part3.json\") as cmm:\n",
    "    collected_messages = json.load(cmm)\n",
    "    \n",
    "for cm in collected_messages:\n",
    "    repo_name = cm[0]\n",
    "    if repo_name in commits_dict_3:\n",
    "        commits_dict_3[repo_name].append(cm[2])\n",
    "    else:\n",
    "        commits_dict_3[repo_name] = [cm[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93191c95-22d6-421c-ab73-9e71247eb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_dict.update(commits_dict_2)\n",
    "commits_dict.update(commits_dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c48be1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CJY0208/react-router-cache-route', 'cookpad/garage', 'jenkinsci/http-request-plugin', 'python273/vk_api', 'veusz/veusz', 'apache/echarts-doc', 'aeternity/aepp-sdk-js', 'spatie/async', 'vsn4ik/bootstrap-submenu', 'ebkr/r2modmanPlus', 'playpauseandstop/rororo', 'ldtteam/minecolonies', 'dotnetcore/FreeSql', 'stepjam/PyRep', 'grigorig/stcgal', 'KnpLabs/KnpMenuBundle', 'Nekmo/telegram-upload', 'heroku/salesforce-bulk', 'ant-design/create-react-app-antd', 'Malinskiy/adam', 'cyrilletuzi/vscode-angular-schematics', 'snoopwpf/snoopwpf', 'stotko/stdgpu', 'ralliejs/rallie', 'DistrictDataLabs/yellowbrick', 'nestjsx/nestjs-typeorm-paginate', 'wellyshen/react-cool-onclickoutside', 'stleamist/BetterSafariView', 'joncampbell123/dosbox-x', 'pubnub/ruby', 'robbievanleeuwen/section-properties', 'qiniu/php-sdk', 'n-elements/core', 'dotintent/react-native-ble-plx', 'facundoolano/google-play-scraper', 'tdiary/tdiary-core', 'ruby/psych', 'stern/stern', 'zalando/zappr', 'alexmojaki/snoop', 'geops/openlayers-editor', 'Yleisradio/homebrew-terraforms', 'khiav223577/deep_pluck', 'NiaOrg/NiaPy', 'jflex-de/jflex', 'calagator/calagator', 'jmcnamara/XlsxWriter', 'BlazeSoftware/atoms', 'collectd/collectd', 'lcn2/calc', 'FedoraQt/adwaita-qt', 'slimphp/Twig-View', 'python-hyper/h11', 'aurelia/cli', 'nimiq/core-js', 'rstudio/profvis', 'igorw/evenement', 'laravel/breeze', 'djberg96/sys-proctable', 'squizlabs/PHP_CodeSniffer', 'ktorio/ktor', 'data-driven-forms/react-forms', 'havakv/pycox', 'yuki-koyama/elasty', 'cpriest/SnapLinksPlus', 'JamesBrill/react-speech-recognition', 'google/digitalbuildings', 'antvis/AVA', 'microsoft/Detours', 'treosh/lighthouse-plugin-field-performance', 'iwalton3/plex-mpv-shim', 'frej/fast-export', 'alefragnani/vscode-numbered-bookmarks', 'masterT/bandcamp-scraper', 'jexuswebserver/JexusManager', 'zhiqwang/yolov5-rt-stack', 'PyPSA/atlite', 'redis-collections/redis-collections', 'adafruit/Adafruit_SSD1306', 'ninja-build/ninja', 'pytorch/text', 'bisohns/search-engine-parser', 'webextension-toolbox/webextension-toolbox', 'lewagon/data-setup', 'spring-projects/spring-batch', 'facebook/metro', 'ever-co/ever-gauzy', 'Sunoo/homebridge-camera-ffmpeg', 'steventhanna/proton', 'nextgenusfs/funannotate', 'Foso/Jetpack-Compose-Playground', 'knuckleswtf/scribe', 'visualboyadvance-m/visualboyadvance-m', 'dream-num/Luckysheet', 'eclipsesource/jsonforms', 'slack-go/slack', 'aburch/simutrans', 'netty/netty-tcnative', 'rlogiacco/CircularBuffer', 'nemuTUI/nemu', 'Bogdanp/molten', 'janko/down', 'druid-io/druid-operator', 'savonrb/httpi', 'evilmartians/lefthook', 'reuben/STT', 'renative-org/renative', 'lighttiger2505/sqls', 'ichiban/prolog', 'CoraLibre/CoraLibre-android-sdk', 'trakt/script.trakt', 'jsdelivr/bootstrapcdn', 'pateketrueke/yrv', 'awtrix/AWTRIX2.0-Controller', 'jmespath/jmespath.py', 'alexmacarthur/typeit', 'phparkitect/arkitect', 'capnproto/pycapnp', 'developit/mitt', 'tobi-wan-kenobi/bumblebee-status', 'USEPA/WNTR', 'roslynpad/roslynpad', 'react-component/util', 'Nepxion/Matrix', 'mangstadt/ez-vcard', 'Ptt-Alertor/ptt-alertor', 'elgorditosalsero/react-gtm-hook', 'daniel5151/ANESE', 'codenamecpp/carnage3d', 'tymondesigns/jwt-auth', 'CookieJarApps/SmartCookieWeb', 'zwug/react-full-page', 'koajs/koa', 'yearn/iearn-finance', 'hhhrrrttt222111/CodeChef', 'google/volley', 'martijnvanbrummelen/nwipe', 'squat/kilo', 'Netflix/metacat', 'actionhero/actionhero-tutorial', 'Azure/static-web-apps-cli', 'redwood/redwood', 'JFormDesigner/FlatLaf', 'gomods/athens', 'sourcegraph/go-diff', 'i18next/i18next-gettext-converter', 'TooTallNate/node-speaker', 'SuperNG6/docker-aria2', 'stellar/java-stellar-sdk', 'tyoma/micro-profiler', 'prontolabs/pronto', 'MaxToyberman/react-native-ssl-pinning', 'kopeio/etcd-manager', 'jbangdev/jbang', 'techtanic/Discounted-Udemy-Course-Enroller', 'kichik/nsis', 'cruft/cruft', 'shogo4405/HaishinKit.swift', 'thanos-io/thanos', 'docker/getting-started', 'linkchecker/linkchecker', 'gatsbyjs/wp-gatsby', 'coding-blocks/CBOnlineApp', 'remap-keys/remap', 'lauris/awesome-scala', 'p5py/p5', 'lchrusciel/ApiTestCase', 'vavr-io/vavr', 'madeso/ride', 'Pircate/CleanJSON', 'komamitsu/fluency', 'jpd002/Play-', 'svg-sprite/gulp-svg-sprite', 'alpinelinux/alpine-chroot-install', 'beberlei/assert', 'dokku/dokku-postgres', 'hardkoded/puppeteer-sharp', 'sebastianbergmann/code-unit-reverse-lookup', 'neurogym/neurogym', 'OriginTrail/ot-node', 'netless-io/flat', 'nroduit/Weasis', 'google/clasp', 'hetznercloud/hcloud-go', 'aiekick/ImGuiFileDialog', 'rudderlabs/rudder-server', 'salsita/node-pg-migrate', 'mscdex/ssh2', 'RailsEventStore/rails_event_store', 'cloudtools/awacs', 'Fody/PropertyChanged', 'textstat/textstat', 'dotMorten/NmeaParser', 'noctuid/tdrop', 'dzaporozhets/six', 'Alkl58/NotEnoughAV1Encodes', 'config4k/config4k', 'k8snetworkplumbingwg/sriov-network-device-plugin', 'noflo/noflo', 'activeadmin/arbre', 'skydoves/sandwich', 'target/goalert', 'nodeSolidServer/node-solid-server', 'hyperledger/burrow', 'leibnitz27/cfr', 'thephpleague/uri', 'WebwareForPython/DBUtils', 'xjh22222228/nav', 'TaleLin/lin-cms-spring-boot', 'SAML-Toolkits/java-saml', 'holgerbrandl/kravis', 'listen1/listen1_chrome_extension', 'archesproject/arches', 'liuyueyi/quick-media', 'textileio/textile', 'VirusTotal/vt-cli', 'hmlendea/gfn-electron', 'jasync-sql/jasync-sql', 'MansaGroup/nrwl-nx-action', 'OAID/TengineKit', 'raeleus/skin-composer', 'xiaody/react-touch-carousel', 'oschwald/maxminddb-golang', 'kornia/kornia', 'simgrid/simgrid', 'OpenMage/magento-lts', 'badgateway/ketting', 'preactjs/preact-router', '5alidz/tiny-schema-validator', 'willnorris/imageproxy', 'rosineygp/mkdkr', 'dynup/kpatch', 'json-parser/json-parser', 'openhab/openhab-core', 'TimOliver/TORoundedButton', 'helloflask/bootstrap-flask', 'SamaneYaghoobi/awesome-persian-youtubers', 'loco-3d/crocoddyl', 'sksamuel/hoplite', 'firehol/firehol', 'vapor/queues', 'HypixelDev/PublicAPI', 'facebookresearch/ParlAI', 'TanStack/react-charts', 'ani-memes/AMII', 'Netflix/dgs-framework', 'texworld/betterbib', 'gleich/fgh', 'letseeqiji/gorobbs', 'rozbo/blog', 'appcraftstudio/buymeacoffee', 'swri-robotics/bag-database', 'vazco/uniforms', 'kronenthaler/mod-pbxproj', 'apptainer/singularity', 'alitajs/alita', 'crystal-lang-tools/vscode-crystal-lang', 'videojs/videojs-contrib-dash', 'TarsCloud/TarsFramework', 'nilaoda/N_m3u8DL-CLI', 'libpd/pd-for-android', 'Strilanc/Quirk', 'aaronn/django-rest-framework-passwordless', 'bgp/bgpq4', 'mautrix/facebook', 'frappe/datatable', 'mitchellkrogza/apache-ultimate-bad-bot-blocker', 'TestableIO/System.IO.Abstractions', 'freeipa/ansible-freeipa', 'bitfinexcom/bitfinex-api-py', 'h5py/h5py', 'testing-library/testing-playground', 'virt-manager/virt-manager', 'tokens-studio/figma-plugin', 'docker/go-connections', 'Kozea/Pyphen', 'actionless/pikaur', 'OpenZWave/open-zwave', 'rizwansoaib/whatsapp-monitor', 'Unity-Technologies/com.unity.netcode.gameobjects', 'python-metar/python-metar', 'koenoe/cocoen', 'dumptyd/vue-css-donut-chart', 'nodejs/nodejs-ko', 'karlstav/cava', 'AFNetworking/AFNetworking', 'zalando-incubator/kube-ingress-aws-controller', 'dereuromark/cakephp-tinyauth', 'Klipper3d/klipper', 'SamVerschueren/listr', 'nats-io/nats.java', 'immutables/immutables', 'vesoft-inc/nebula-python', 'pyamg/pyamg', 'jrief/djangocms-cascade', 'KeeTrayTOTP/KeeTrayTOTP', 'sindresorhus/p-queue', 'microsoft/PowerToys', 'keremvaris/Sennedjem', 'SirVer/ultisnips', 'CodeForPhilly/chime', 'gabrielfalcao/sure', 'tighten/lambo', 'textX/textX', 'mapbox/protozero', 'jshttp/mime-types', 'auraphp/Aura.Di', 'terser/terser', 'HSLdevcom/digitransit-ui', 'cclauss/Ten-lines-or-less', 'Dhaval2404/ImagePicker', 'redis-store/redis-rails', 'techdivision/import', 'nirgn975/generator-jekyll-starter-kit', 'babenkoivan/elastic-scout-driver-plus', 'steve228uk/YouTube-Music', 'DanTheMan827/ios-app-signer', 'Netflix/photon', 'MikePopoloski/slang', 'remcohaszing/pywakeonlan', 'googleapis/signet', 'jhackshaw/ofnotes', 'relayphp/Relay.Relay', 'opendistro-for-elasticsearch/alerting-kibana-plugin', 'adhocore/urlsh', 'doctrine/phpcr-odm', 'square/sharkey', 'hermanTenuki/ASCII-Generator.site', 'thecodrr/fdir', 'SmallChi/JT1078', 'mattallty/Caporal.js', 'pubkey/rxdb', 'apache/hop', 'iouAkira/someDockerfile', 'genuinetools/img', 'Electroid/SportPaper', 'zyfra/ebonite', 'toddams/RazorLight', 'pcko1/etherscan-python', 'libimobiledevice/libusbmuxd', 'webanalyzer/rules', 'exercism/cli', 'klen/muffin', 'trentm/json', 'lidatong/dataclasses-json', 'google/yapf', 'm3dev/gokart', 'openthread/wpantund', 'andrix/python-snappy', 'schibsted/jslt', 'casbin/casnode', 'Biarity/Sieve', 'tardis-dev/serum-vial', 'icerockdev/libs.kmp.icerock.dev', 'GoogleChromeLabs/ProjectVisBug', 'dotpot/InAppPy', 'Turbo87/intellij-emberjs', 'kubernetes-sigs/kui', 'esrlabs/chipmunk', 'pigpigyyy/Yuescript', 'jmhodges/howsmyssl', 'geist-org/geist-ui', 'Kozea/CairoSVG', 'Azure/azure-resource-manager-schemas', 'jazzband/django-payments', 'M5ez/M5ez', 'martinpitt/umockdev', 'noahsark769/cifilter.io', '2fd/graphdoc', 'doric-pub/Doric', 'leo-editor/leo-editor', 'fumeapp/laranuxt', 'electron/forge', 'mongodb/mongo-swift-driver', 'boostorg/safe_numerics', 'macropin/django-registration', 'felix-fly/v2ray-openwrt', 'corda/corda', 'nschloe/github-trends', 'toggl/track-extension', 'indilib/indi', 'rpearce/react-medium-image-zoom', 'nanmu42/orly', 'estruyf/vscode-front-matter', 'jziolkowski/tdm', 'ruarai/CompilePal', 'mruby/mruby', 'chunyenHuang/hummusRecipe', 'lepture/authlib', 'rom-rb/rom-rails', 'data-uri/datauri', 'nanostores/nanostores', 'ansible-community/molecule-vagrant', 'cc-archive/ccsearch-browser-extension', 'yiisoft/yii2-mongodb', 'xiph/flac', 'kscripting/kscript', 'xkcoding/spring-boot-demo', 'Anapher/Strive', 'Tyrrrz/Onova', 'Paradigm4/SciDB-Py', 'aaronpowell/httpstatus', 'DonJayamanne/gitHistoryVSCode', 'coston/react-super-responsive-table', 'oazapfts/oazapfts', 'KryptonMC/Krypton', 'getsentry/self-hosted', 'Bedrock-Layouts/Bedrock', 'apache/cordova-lib', 'wireservice/agate', 'Stvad/CrowdAnki', 'Trustroots/trustroots', 'trusttoken/contracts-pre22', 'pgmpy/pgmpy', 'getsentry/sentry-go', '1pkg/gopium', 'mbj/unparser', 'flobz/psa_car_controller', 'airlift/airlift', 'eclipse/paho.mqtt.c', 'airbnb/lottie-android', 'KubeOperator/webkubectl', 'Icinga/icinga2', 'dddjava/jig', 'thenativeweb/wolkenkit', 'apereo/java-cas-client', 'atom/spell-check', 'Erudika/para', 'gtimelog/gtimelog', 'titarenko/OAuth2', 'unosquare/embedio', 'Ocramius/GeneratedHydrator', 'scikit-hep/scikit-hep', 'helmwave/helmwave', 'caprica/vlcj', 'filhodanuvem/gitql', 'nmap/ncrack', 'commitizen-tools/commitizen', 'raviqqe/muffet', 'damienbod/AspNetCoreCertificates', 'rjrjr/compose-backstack', 'novoid/filetags', 'StarEliteCore/Nebula.Admin', 'readium/r2-testapp-kotlin', 'lsds/KungFu', 'omniauth/omniauth', 'atymic/twitter', 'adlered/bolo-solo', 'wechaty/getting-started', 'tmobile/jazz', 'micro-ROS/micro_ros_arduino', 'mozillazg/go-pinyin', 'sitkevij/awesome-video', 'Thinkmill/manypkg', 'epi052/recon-pipeline', 'mauricioaniche/ck', 'jupeter/clean-code-php', 'theforeman/foreman_ansible', 'wintoncode/Winton.Extensions.Configuration.Consul', 'microsoft/vscode-python-devicesimulator', 'HiddenRamblings/TagMo', 'rbanffy/3270font', 'kubeops/config-syncer', 'petergoldstein/dalli', 'HazyResearch/fonduer', 'vercel/fun', 'ivmartel/dwv', 'mbj4668/pyang', 'uber/artist', 'sous-chefs/openvpn', 'Viladoman/CompileScore', 'software-mansion/react-native-gesture-handler', 'FleekHQ/space-daemon', 'securingsincity/react-ace', 'aap/librw', 'CocoaPods/Xcodeproj', 'vuejs/vue-eslint-parser', 'pallets/flask', 'amundsen-io/amundsenfrontendlibrary', 'libgit2/pygit2', 'ainilili/ratel', 'XML-Security/signxml', 'ghosh/Micromodal', 'ahay/src', 'apache/incubator-tuweni', 'wang-bin/avbuild', 'django-money/django-money', 'spockframework/spock', 'libsndfile/libsndfile', 'okuramasafumi/alba', 'chicio/ID3TagEditor', 'laravel-notification-channels/telegram', 'wix/repluggable', 'vercel-community/deno', 'D-X-Y/Awesome-AutoDL', 'reZach/secure-electron-template', 'nsfw-filter/nsfw-filter', 'Ryzee119/ogx360', 'redpanda-data/kminion', 'ctu-mrs/mrs_uav_system', 'RediSearch/redisearch-py', 'mogemimi/pomdog', 'react-bootstrap/react-overlays', 'gentoo/portage', 'boost-ext/ut', 'Rinnegatamante/lpp-vita', 'ai/size-limit', 'BeyondDimension/SteamTools', 'centrifugal/centrifuge', 'single-spa/single-spa', 'storybookjs/react-inspector', 'davidlatwe/montydb', 'ClaudiuGeorgiu/PlaystoreDownloader', 'cpprefjp/site', 'muhammadsammy/tailwindcss-classnames', 'fastify/middie', 'tradle/react-native-udp', 'private-octopus/picoquic', 'ThePBone/GalaxyBudsClient', 'pretrehr/Sports-betting', 'AcademySoftwareFoundation/openexr', 'pierre-emmanuelJ/iptv-proxy', 'tuna/opentuna', 'deepjavalibrary/djl-demo', 'allenai/allenact', 'camunda/camunda-external-task-client-js', 'testingisdocumenting/webtau', 'jaegertracing/jaeger-client-node', 'jasonacox/tinytuya', 'iNPUTmice/lttrs-android', 'freewym/espresso', 'sysgears/webpack-virtual-modules', 'moby/buildkit', 'Eeems-Org/oxide', 'tensorflow/recommenders', 'marcandre/backports', 'wessberg/rollup-plugin-ts', 'apache/cordova-cli', 'nschloe/stressberry', 'showwin/speedtest-go', 'mikepenz/MaterialDrawer', 'yomorun/yomo', 'moshebe/gebug', 'twbs/stylelint-config-twbs-bootstrap', 'ddinan/tsuyo', 'NVIDIA/aistore', 'algoan/nestjs-components', 'requests/requests-kerberos', 'kivy/pyjnius', 'brndnmtthws/conky', 'nirui/sshwifty', 'github/graphql-client', 'ipfs/go-ds-s3', 'rednafi/fastapi-nano', 'philipperemy/stanford-openie-python', 'ralphbean/bugwarrior', 'youzan/vant-weapp', 'GIScience/openpoiservice', 'shazow/ssh-chat', 'Dmitri-Sintsov/django-jinja-knockout', 'protectwise/troika', 'hetznercloud/hcloud-cloud-controller-manager', 'dkandalov/live-plugin', 'gitlabform/gitlabform', 'CacheControl/hippie-swagger', 'digiteinfotech/kairon', 'restic/rest-server', 'kriasoft/relay-starter-kit', 'cr0hn/aiohttp-swagger', 'wasabeef/transformers', 'libcpr/cpr', 'christopherread/Obvs', 'cgriego/active_attr', 'thought-machine/please', 'react-native-elements/react-native-elements', 'dalibor/octoshark', 'Tencent/bk-sops', 'carbon-design-system/gatsby-theme-carbon', 'FormidableLabs/renature', 'albertogeniola/MerossIot', 'zumba/swivel', 'microsoft/appcenter-cli', 'ethz-asl/aerial_mapper', 'dfinity/linkedup', 'sysrepo/sysrepo', 'rstudio/learnr', 'MichaReiser/llvm-node', 'linkedin/transport', 'mediathekview/MediathekView', 'yzhao062/pyod', 'yashaka/selene', 'stylelint/stylelint-config-recommended', 'aws/aws-node-termination-handler', 'iovisor/gobpf', 'ether/ueberDB', 'HandBrake/HandBrake-docs', 'castlemock/castlemock', 'ffftp/ffftp', 'vbenjs/vue-vben-admin', 'alibaba/rax', 'good-idea/sane-shopify', 'puemos/hls-downloader', 'karen-irc/option-t', 'Remora/Remora.Discord', 'xobotyi/await-of', 'moq/Moq.AutoMocker', 'jirka-h/haveged', 'Khan/math-input', 'damnever/pigar', 'ical4j/ical4j', 'MightyCreak/mesamatrix', 'vmagamedov/grpclib', 'nextcloud/news', 'EasyPost/easypost-php', 'ngageoint/geopackage-js', 'nickg/nvc', 'orocos/orocos_kinematics_dynamics', 'jupyter-xeus/xeus-python', 'itzg/docker-minecraft-bedrock-server', '256dpi/arduino-mqtt', 'jonrau1/ElectricEye', 'arunkumar9t2/scabbard', 'mangostwo/server', 'tenseijs/tensei', 'tw-in-js/twind', 'BackendStack21/fast-gateway', 'obgm/libcoap', 'akfamily/akshare', 'sj26/mailcatcher', 'chalk/chalk', 'milesmcc/shynet', 'yang991178/fluent-reader', 'firebase/snippets-web', 'jamesgeorge007/scaffold-static', 'danya/react-local', 'geany/geany', 'justinmayer/virtualfish', 'drush-ops/drush', 'GoogleCloudPlatform/ruby-docker', 'buddyboss/buddyboss-platform', 'Josee9988/project-template', 'sql-machine-learning/sqlflow', 'andrew-gresyk/HFSM2', 'janfreyberg/superintendent', 'ziglang/vscode-zig', 'nfrechette/acl', 'GodotVR/godot_openvr', 'test-unit/test-unit', 'jens-maus/RaspberryMatic', 'weibocom/motan-go', 'percona/percona-backup-mongodb', 'lc-soft/LCUI', 'collectiveidea/awesome_nested_set', 'albertomosconi/foss-apps', 'uploadcare/uploadcare-widget', 'pennsignals/chime', 'sitespeedio/browsertime', 'nipy/nibabel', 'vuejs/vue-codemod', 'Tencent/QT4A', 'Orange-Cyberdefense/arsenal', 'KaustubhPatange/Moviesy', 'alexflint/go-arg', 'vuejs/vue-jest', 'EmbeddedRPC/erpc', 'Netflix/dyno', 'Haehnchen/idea-php-laravel-plugin', 'R1j1t/contextualSpellCheck', 'cbeuw/Cloak', '4refr0nt/ESPlorer', 'aimhubio/aim', 'gnuradio/pybombs', 'doctrine/DoctrineBundle', 'uraimo/SwiftyGPIO', 'TyMaszWeb/django-cookie-law', 'FujiNetWIFI/fujinet-platformio', 'google/pprof', 'isaacs/node-graceful-fs', 'ataradov/edbg', 'winstonjs/winston', 'kean/Pulse', 'howtocards/frontend', 'archivy/archivy', 'YusukeHosonuma/SwiftPrettyPrint', 'openebs/maya', 'darukjs/daruk', 'rootstrap/ios-base', 'mdias/rs_asio', 'linlinjava/litemall', 'Ericsson/CodeCompass', 'DeFiCh/app', 'Mantle/Mantle', 'nette/di', 'spatie/laravel-export', 'pyscaffold/pyscaffold', 'Azure/kubernetes-volume-drivers', 'avrae/avrae', 'kpfromer/nestjs-typegoose', 'Smashing/smashing', 'davidwengier/Trains.NET', 'graphql-editor/graphql-editor', 'GraphQL-Portal/graphql-portal', 'tsl0922/ttyd', 'lonnieezell/myth-auth', 'openocd-org/openocd', 'tidev/alloy', 'multiformats/go-multihash', 'deepmind/open_spiel', 'huggingface/transformers', 'TypeStrong/fork-ts-checker-webpack-plugin', 'jazzband/django-admin2', 'potato4d/nuxt-basic-auth-module', '99designs/gqlgen', 'nextcloud/ocsms', '18F/uswds-jekyll', 'cdk8s-team/cdk8s', 'jfrog/build-info', 'jenkinsci/dingtalk-plugin', 'yiisoft/yii2-swiftmailer', 'tmm1/stackprof', 'sindresorhus/on-change', 'rizsotto/Bear', 'khornberg/elasticpypi', 'colinhacks/zod', 'janaagaard75/expo-and-typescript', 'boutproject/BOUT-dev', 'bluehalo/node-fhir-server-core', 'Javacord/Javacord', 'cisco/mindmeld', 'mozilla/DeepSpeech', 'apache/servicecomb-java-chassis', 'libyal/libpff', 'iSoron/uhabits', 'GAM-team/got-your-back', 'kobra-dev/Kobra', 'Lyken17/pytorch-OpCounter', 'marciovsena/abibliadigital', 'sublimelsp/LSP', 'FairwindsOps/reckoner', 'feast-dev/feast', 'wkentaro/fcn', 'mattn/memo', 'osrf/rocker', 'haveno-dex/haveno', 'OrleansContrib/OrleansDashboard', 'keis/git-fixup', 'appscode/osm', 'intel/ad-rss-lib', 'Cyclenerd/postinstall', 'PatchworkMC/patchwork-api', 'wangerzi/layui-excel', 'symfony-cmf/routing-bundle', 'C2FO/vfs', 'neogeny/TatSu', 'pwa-builder/CloudAPK', 'bagisto/bagisto', 'berialjs/berial', 'comotion/VSF', 'Finbuckle/Finbuckle.MultiTenant', 'nipy/nipype', 'amilajack/eslint-plugin-flowtype-errors', 'vapor/jwt', 'spatie/crawler', 'Renanse/Ardor3D', 'AlaSQL/alasql', 'studentinsights/studentinsights', 'soraxas/echo360', 'deepcharles/ruptures', 'tdewolff/canvas', 'SpartanJ/efsw', 'CenterForOpenScience/ember-osf-web', 'magnusbaeck/logstash-filter-verifier', 'zehome/MLVPN', 'kisslinux/kiss', 'closeio/ciso8601', 'erkkah/tigr', 'apache/mina-sshd', 'PyCQA/flake8-bugbear', 'RidgeRun/gstd-1.x', 'weichsel/ZIPFoundation', 'libp2p/go-libp2p-kad-dht', 'tenderlove/tenderjit', 'mglaman/drupalorg-cli', 'graphql-compose/graphql-compose-examples', 'gkozlenko/node-video-lib', 'reactjs/tr.reactjs.org', 'ralfstuckert/pdfbox-layout', 'keirf/greaseweazle', 'discordjs/Commando', 'typicode/json-server', 'forcedotcom/sfdx-scanner', 'fenichelar/ember-simple-auth-token', 'humanmade/S3-Uploads', 'YaoZeyuan/zhihuhelp', 'illuminate/console', 'ObKo/stm32-cmake', 'latchset/tang', 'manim-kindergarten/manim_document_zh', 'miekg/dns', 'sapphiredev/framework', 'stackrox/kube-linter', 'gnuradio/volk', 'tancredi/fantasticon', 'golevelup/nestjs', 'webpro/dotfiles', 'build-cpp/cmkr', 'Shunichi09/PythonLinearNonlinearControl', 'graphia-app/graphia', 'sebastienros/esprima-dotnet', 'primer/github-vscode-theme', 'OpenTracksApp/OpenTracks', 'acgist/snail', 'salu133445/muspy', 'leocavalcante/siler', 'zhanghai/MaterialFiles', 'LKI/chinese-calendar', 'spatie/laravel-webhook-client', 'grame-cncm/faust', 'jsx-eslint/jsx-ast-utils', 'libvirt/libvirt-python', 'egoist/tsup', 'canonical/raft', 'jelhan/croodle', 'ryanmcalister/unotes', 'Wikidata/Wikidata-Toolkit', 'hyochan/react-native-audio-recorder-player', 'frictionlessdata/datapackage-pipelines', 'python-adaptive/adaptive', 'thomasloven/hass-browser_mod', 'kellyjonbrazil/jc', 'MichaelSolati/geofirestore-js', 'serenity-bdd/serenity-cucumber-starter', 'mozilla/cubeb', 'Serverless-Devs/Serverless-Devs'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba3ebc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commits_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60a097b5-9cc4-4c7f-ad50-e4f24e6a2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_impact_1 = calc_skip_impact(data_set, repos_list_1, commits_dict)\n",
    "skip_impact_2 = calc_skip_impact(data_set, repos_list_2, commits_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819d7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"skip_workflow\"]={\n",
    "    \"paid\":{\n",
    "        \"adoption\": skip_impact_1[0],\n",
    "        \"impacted_runs\": skip_impact_1[1],\n",
    "        \"time_impact\": skip_impact_1[2],\n",
    "        \"cost_impact\": skip_impact_1[3]\n",
    "    },\n",
    "    \"free\":\n",
    "    {\n",
    "        \"adoption\": skip_impact_2[0],\n",
    "        \"impacted_runs\": skip_impact_2[1],\n",
    "        \"time_impact\": skip_impact_2[2],\n",
    "        \"cost_impact\": skip_impact_2[3]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3188f8-283f-407e-b025-140106c4a99b",
   "metadata": {},
   "source": [
    "## cache action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e807a60-357d-4f84-a5a6-25c39f1068a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pure_hashes.json\") as phj:\n",
    "    pure_hashes =  json.load(phj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a61b7d39-f729-4de7-a940-4047ebeba5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_commits = []\n",
    "with open(\"collected_commits_save_poins.json\") as ccs:\n",
    "    collected_commits += json.load(ccs)\n",
    "\n",
    "with open(\"collected_commits_save_point_part2.json\") as ccsp:\n",
    "    collected_commits += json.load(ccsp)\n",
    "\n",
    "#with open(\"collected_commits_save_point_part3.json\") as ccsp:\n",
    "#    collected_commits += json.load(ccsp)\n",
    "\n",
    "with open(\"collected_commits_save_point_part4.json\") as ccsp:\n",
    "    collected_commits += json.load(ccsp)\n",
    "\n",
    "new_collected_commits = []\n",
    "for commit in collected_commits:\n",
    "    new_added = []\n",
    "    new_deleted = []\n",
    "    new_modified = []\n",
    "    \n",
    "    for c in commit[\"Added\"]:\n",
    "        if c[\"commit_hash\"] in pure_hashes:\n",
    "            new_added.append(c)\n",
    "    \n",
    "    for c in commit[\"Deleted\"]:\n",
    "        if c[\"commit_hash\"] in pure_hashes:\n",
    "            new_deleted.append(c)\n",
    "    \n",
    "    for c in commit[\"Modified\"]:\n",
    "        if c[\"commit_hash\"] in pure_hashes:\n",
    "            new_modified.append(c)\n",
    "    \n",
    "    if len(new_added) + len(new_deleted) +len(new_modified) != 0:\n",
    "        new_collected_commits.append({\n",
    "            \"Added\": new_added,\n",
    "            \"Deleted\": new_deleted,\n",
    "            \"Modified\": new_modified\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcf01893-5550-433c-ba29-adbb3620d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_usage = get_optimization_usage(collected_commits, optimization=\"cache@v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bd1b9-53ff-43df-ba6b-2165f2a9bcad",
   "metadata": {},
   "source": [
    "### Impacted repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e789749-420e-4e76-ba5e-c0914b6021d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_with = set([x[0] for x in cache_usage[\"created_with_optimization\"]])\n",
    "added = set([x[0] for x in cache_usage[\"optimization_removed\"]])\n",
    "removed = set([x[0] for x in cache_usage[\"optimization_added\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a21e7c6-3218-4f79-9b55-537ed5fb9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "adoption1 = len((created_with|\n",
    "    added|\n",
    "    removed) & set(list_1_names)) / len(list_1_names)\n",
    "\n",
    "adoption2 = len((created_with|\n",
    "    added|\n",
    "    removed) & set(list_2_names)) / len(list_2_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b8024-6f9f-4e94-bd52-ccda6efa4887",
   "metadata": {},
   "source": [
    "### Prevalence and Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b55b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_1, cost_1 = calc_cache_impact(collected_commits, data_set, repos_list_1)\n",
    "time_2, cost_2 = calc_cache_impact(new_collected_commits, data_set, repos_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091a27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"cache\"]={\n",
    "    \"paid\":{\n",
    "        \"adoption\": adoption1*100,\n",
    "        \"impacted_runs\": 100.0, # by design\n",
    "        \"time_impact\": time_1 * 100 * -1,\n",
    "        \"cost_impact\": cost_1 * -1\n",
    "    },\n",
    "    \"free\":\n",
    "    {\n",
    "        \"adoption\": adoption2*100,\n",
    "        \"impacted_runs\": 100.0, # by design\n",
    "        \"time_impact\": time_2 * 100 * -1 / 2,\n",
    "        \"cost_impact\": cost_2 * -1 / 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2afe1033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4000000000000004"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(str(0.03467)[:5])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a231c67-4cba-48a0-8a7f-d2ac6dde16a8",
   "metadata": {},
   "source": [
    "## filtering target files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e3dc0e3-58c5-4257-8beb-f67960f64688",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_ignore = get_optimization_ts(collected_commits, optimization=\"paths-ignore:\")\n",
    "paths = get_optimization_ts(collected_commits, optimization=\"paths:\")\n",
    "all_repos = data_set.get_all_repositories()\n",
    "repos_1_names = all_repos[all_repos.id.isin(repos_list_1)].full_name.to_list()\n",
    "repos_2_names = all_repos[all_repos.id.isin(repos_list_2)].full_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c0b0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repos = data_set.get_all_repositories()\n",
    "paths_ignore = get_optimization_ts(collected_commits, optimization=\"paths-ignore:\")\n",
    "paths = get_optimization_ts(collected_commits, optimization=\"paths:\")\n",
    "paths_ignore_usage = get_optimization_ts(collected_commits, optimization=\"paths-ignore:\")\n",
    "paths_usage = get_optimization_ts(collected_commits, optimization=\"paths:\")\n",
    "cancel_inprogress = get_optimization_ts(collected_commits, optimization=\"cancel-in-progress\")\n",
    "\n",
    "#\n",
    "repos_1_names = all_repos[all_repos.id.isin(repos_list_1)].full_name.to_list()\n",
    "repos_2_names = all_repos[all_repos.id.isin(repos_list_2)].full_name.to_list()\n",
    "\n",
    "filter_adoption_1 = len(\n",
    "    set([pi[0] for pi in paths_ignore if pi[0] in repos_1_names])|set([p[0] for p in paths if p[0] in repos_1_names])\n",
    "    )/len(repos_1_names) * 100\n",
    "\n",
    "filter_adoption_2 = len(\n",
    "    set([pi[0] for pi in paths_ignore if pi[0] in repos_2_names])|set([p[0] for p in paths if p[0] in repos_2_names])\n",
    "    )/len(repos_2_names) * 100\n",
    "\n",
    "paths_ignore = [pi for pi in paths_ignore if pi[0] in repos_1_names]\n",
    "paths = [pi for pi in paths if pi[0] in repos_1_names]\n",
    "runs_repos = all_runs.merge(all_repos, left_on=\"repo_id\", right_on=\"id\")\n",
    "runs_repos[\"start_ts\"] = runs_repos.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "optimized_runs = []\n",
    "possible_ids = []\n",
    "for pi in paths_ignore:\n",
    "    possible_runs = runs_repos[(runs_repos.full_name==pi[0]) & (runs_repos.workflow_file==\".github/workflows/\"+pi[1]) & (runs_repos.start_ts>pi[2]) & (runs_repos.start_ts<pi[3])]\n",
    "    possible_runs = possible_runs.sort_values(\"start_ts\")\n",
    "    optimized_runs.extend(possible_runs[possible_runs.conclusion==\"skipped\"].id_x.to_list())\n",
    "    possible_ids.extend(possible_runs.id_x.to_list())\n",
    "for pi in paths:\n",
    "    possible_runs = runs_repos[(runs_repos.full_name==pi[0]) & (runs_repos.workflow_file==\".github/workflows/\"+pi[1]) & (runs_repos.start_ts>pi[2]) & (runs_repos.start_ts<pi[3])]\n",
    "    possible_runs = possible_runs.sort_values(\"start_ts\")\n",
    "    optimized_runs.extend(possible_runs[possible_runs.conclusion==\"skipped\"].id_x.to_list())\n",
    "    possible_ids.extend(possible_runs.id_x.to_list())\n",
    "runs_total_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\"}).reset_index()\n",
    "runs_repos = runs_repos.merge(runs_total_time, left_on=\"id_x\", right_on=\"run_id\")\n",
    "workflow_mean = runs_repos[runs_repos.workflow_id.isin(runs_repos[runs_repos.id_x.isin(optimized_runs)].workflow_id)].groupby(\"workflow_id\").agg({\"up_time\": \"mean\"}).reset_index()\n",
    "runs_repos[runs_repos.id_x.isin(optimized_runs)].\\\n",
    "merge(workflow_mean, left_on=\"workflow_id\", right_on=\"workflow_id\").up_time_y.sum()/runs_repos[runs_repos.id_x.isin(possible_ids)].up_time.sum()*100\n",
    "start_ts_min_max = runs_repos[runs_repos.id_x.isin(possible_ids)].groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in start_ts_min_max.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "total_possible_time1 = total_start_ts/(12*30*24*3600)\n",
    "save_cost1 = runs_repos[runs_repos.id_x.isin(possible_ids)].up_time.sum()/total_possible_time1/60 * 0.008*1.52*0.005\n",
    "imp_runs_1 = len(optimized_runs)/len(possible_ids)*100\n",
    "imp_time_1 = runs_repos[runs_repos.run_id.isin(optimized_runs)].up_time.sum()/(12*30*24*3600) / total_possible_time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4c0b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_ignore = get_optimization_ts(collected_commits, optimization=\"paths-ignore:\")\n",
    "paths = get_optimization_ts(collected_commits, optimization=\"paths:\")\n",
    "paths_ignore_usage = get_optimization_ts(collected_commits, optimization=\"paths-ignore:\")\n",
    "paths_usage = get_optimization_ts(collected_commits, optimization=\"paths:\")\n",
    "cancel_inprogress = get_optimization_ts(collected_commits, optimization=\"cancel-in-progress\")\n",
    "\n",
    "repos_1_names = all_repos[all_repos.id.isin(repos_list_1)].full_name.to_list()\n",
    "repos_2_names = all_repos[all_repos.id.isin(repos_list_2)].full_name.to_list()\n",
    "\n",
    "filter_adoption_1 = len(\n",
    "    set([pi[0] for pi in paths_ignore if pi[0] in repos_1_names])|set([p[0] for p in paths if p[0] in repos_1_names])\n",
    "    )/len(repos_1_names) * 100\n",
    "\n",
    "filter_adoption_2 = len(\n",
    "    set([pi[0] for pi in paths_ignore if pi[0] in repos_2_names])|set([p[0] for p in paths if p[0] in repos_2_names])\n",
    "    )/len(repos_2_names) * 100\n",
    "\n",
    "paths_ignore = [pi for pi in paths_ignore if pi[0] in repos_2_names]\n",
    "paths = [pi for pi in paths if pi[0] in repos_2_names]\n",
    "runs_repos = all_runs.merge(all_repos, left_on=\"repo_id\", right_on=\"id\")\n",
    "runs_repos[\"start_ts\"] = runs_repos.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "optimized_runs = []\n",
    "possible_ids = []\n",
    "for pi in paths_ignore:\n",
    "    possible_runs = runs_repos[(runs_repos.full_name==pi[0]) & (runs_repos.workflow_file==\".github/workflows/\"+pi[1]) & (runs_repos.start_ts>pi[2]) & (runs_repos.start_ts<pi[3])]\n",
    "    possible_runs = possible_runs.sort_values(\"start_ts\")\n",
    "    optimized_runs.extend(possible_runs[possible_runs.conclusion==\"skipped\"].id_x.to_list())\n",
    "    possible_ids.extend(possible_runs.id_x.to_list())\n",
    "for pi in paths:\n",
    "    possible_runs = runs_repos[(runs_repos.full_name==pi[0]) & (runs_repos.workflow_file==\".github/workflows/\"+pi[1]) & (runs_repos.start_ts>pi[2]) & (runs_repos.start_ts<pi[3])]\n",
    "    possible_runs = possible_runs.sort_values(\"start_ts\")\n",
    "    optimized_runs.extend(possible_runs[possible_runs.conclusion==\"skipped\"].id_x.to_list())\n",
    "    possible_ids.extend(possible_runs.id_x.to_list())\n",
    "runs_total_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\"}).reset_index()\n",
    "runs_repos = runs_repos.merge(runs_total_time, left_on=\"id_x\", right_on=\"run_id\")\n",
    "workflow_mean = runs_repos[runs_repos.workflow_id.isin(runs_repos[runs_repos.id_x.isin(optimized_runs)].workflow_id)].groupby(\"workflow_id\").agg({\"up_time\": \"mean\"}).reset_index()\n",
    "runs_repos[runs_repos.id_x.isin(optimized_runs)].\\\n",
    "merge(workflow_mean, left_on=\"workflow_id\", right_on=\"workflow_id\").up_time_y.sum()/runs_repos[runs_repos.id_x.isin(possible_ids)].up_time.sum()*100\n",
    "start_ts_min_max = runs_repos[runs_repos.id_x.isin(possible_ids)].groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index()\n",
    "total_start_ts = 0\n",
    "for i, row in start_ts_min_max.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "total_possible_time2 = total_start_ts/(12*30*24*3600)\n",
    "save_cost2 = runs_repos[runs_repos.id_x.isin(possible_ids)].up_time.sum()/total_possible_time2/60 * 0.008*1.52*0.005\n",
    "imp_runs_2 = len(optimized_runs)/len(possible_ids)*100\n",
    "imp_time_2 = runs_repos[runs_repos.run_id.isin(optimized_runs)].up_time.sum()/(12*30*24*3600) / total_possible_time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9363db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"filtering_target_files\"]={\n",
    "    \"paid\":{\n",
    "        \"adoption\": filter_adoption_1,\n",
    "        \"impacted_runs\": imp_runs_1,\n",
    "        \"time_impact\": imp_time_1,\n",
    "        \"cost_impact\": save_cost1\n",
    "    },\n",
    "    \"free\":\n",
    "    {\n",
    "        \"adoption\": filter_adoption_2,\n",
    "        \"impacted_runs\": imp_runs_2,\n",
    "        \"time_impact\": imp_time_1,\n",
    "        \"cost_impact\": save_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188203d6-d4e4-41f2-8d10-d6a2be1131ee",
   "metadata": {},
   "source": [
    "## fail fast option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff81ebb8-543f-4e9f-b951-f163bb893ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_fast = get_optimization_usage(collected_commits, optimization=\"fail-fast:false\")\n",
    "repos_1_names = all_repos[all_repos.id.isin(repos_list_1)].full_name.to_list()\n",
    "len(set([x[0] for x in fail_fast[\"optimization_removed\"] if x[0] in repos_1_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cd46806-2e8a-41dc-a129-8dc83fd8dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_off1 = len(set([x[0] for x in fail_fast[\"created_with_optimization\"] if x[0] in list_1_names])-set([x[0] for x in fail_fast[\"optimization_removed\"] if x[0] in list_1_names]))\n",
    "len_off2 = len(set([x[0] for x in fail_fast[\"created_with_optimization\"] if x[0] in list_2_names])-set([x[0] for x in fail_fast[\"optimization_removed\"] if x[0] in list_2_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a8e6d4b-cb57-422e-b727-1eb1c9dafaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adoption_1 = 100 - len_off1/len(list_1_names)*100\n",
    "adoption_2 = 100 - len_off2/len(list_2_names)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "306aa4f7-b3e3-45fd-a140-9c14616b8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_fast_ts = get_optimization_ts(collected_commits, optimization=\"fail-fast:false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "700d7617-8f82-4328-922d-73ff32cfd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = data_set.get_all_runs()\n",
    "all_jobs = data_set.get_all_jobs()\n",
    "all_repos = data_set.get_all_repositories()\n",
    "runs_total_time = all_jobs.groupby(\"run_id\").agg({\"up_time\": \"sum\"}).reset_index()\n",
    "all_runs = all_runs.merge(runs_total_time, left_on=\"id\", right_on=\"run_id\")\n",
    "all_runs[\"start_ts\"] = all_runs.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "runs_repos = all_runs.merge(all_repos[[\"id\", \"full_name\"]], left_on=\"repo_id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55bef7c5-5779-484b-91de-a0fda55b46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_fast_false = []\n",
    "for pi in fail_fast_ts:\n",
    "    if pi[0] in list_2_names:\n",
    "        possible_runs = runs_repos[(runs_repos.full_name==pi[0]) & (runs_repos.workflow_file==\".github/workflows/\"+pi[1]) & (runs_repos.start_ts>pi[2]) & (runs_repos.start_ts<pi[3])]\n",
    "        possible_runs = possible_runs.sort_values(\"start_ts\")\n",
    "        fail_fast_false.extend(possible_runs.id_x.to_list())\n",
    "        #optimized_runs.extend(possible_runs[possible_runs.conclusion==\"skipped\"].id_x.to_list())\n",
    "        #possible_ids.extend(possible_runs.id_x.to_list())\n",
    "no_fail_fast_runs = all_runs[~all_runs.id.isin(fail_fast_false)]\n",
    "jobs_matrix = all_jobs[((all_jobs.name.str.contains(\"\\(\")) | (all_jobs.name.str.contains(\"matrix\")))]\n",
    "optimized_runs = no_fail_fast_runs[(no_fail_fast_runs.id.isin(jobs_matrix.run_id)) & (no_fail_fast_runs.conclusion==\"failure\")]\n",
    "no_fail_fast_success = no_fail_fast_runs[no_fail_fast_runs.conclusion==\"success\"]\n",
    "saved_time = []\n",
    "\n",
    "for i, row in optimized_runs.iterrows():\n",
    "    start_ts = row[\"start_ts\"]\n",
    "    success_df = no_fail_fast_success[(no_fail_fast_success.workflow_id == row[\"workflow_id\"])]\n",
    "    if success_df.shape[0] != 0:\n",
    "        success_time = success_df[(success_df.workflow_id == row[\"workflow_id\"])].up_time.to_list()[0]\n",
    "        saved_time.append(success_time - row[\"up_time\"])\n",
    "saved_time2 = sum(saved_time)/(no_fail_fast_runs.up_time.sum()+sum(saved_time))*100\n",
    "impacted_runs2 = optimized_runs.shape[0] / all_runs.shape[0]\n",
    "sum_start_ts = 0\n",
    "for i, row in no_fail_fast_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index().iterrows():\n",
    "    sum_start_ts += row[\"max\"] - row[\"min\"]\n",
    "sum_start_ts = sum_start_ts/(12*30*24*3600)\n",
    "save_cost2 = sum(saved_time)/sum_start_ts * 0.008 * 1.52 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3465e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_fast_false = []\n",
    "for pi in fail_fast_ts:\n",
    "    if pi[0] in list_1_names:\n",
    "        possible_runs = runs_repos[(runs_repos.full_name==pi[0]) & (runs_repos.workflow_file==\".github/workflows/\"+pi[1]) & (runs_repos.start_ts>pi[2]) & (runs_repos.start_ts<pi[3])]\n",
    "        possible_runs = possible_runs.sort_values(\"start_ts\")\n",
    "        fail_fast_false.extend(possible_runs.id_x.to_list())\n",
    "        #optimized_runs.extend(possible_runs[possible_runs.conclusion==\"skipped\"].id_x.to_list())\n",
    "        #possible_ids.extend(possible_runs.id_x.to_list())\n",
    "no_fail_fast_runs = all_runs[~all_runs.id.isin(fail_fast_false)]\n",
    "jobs_matrix = all_jobs[((all_jobs.name.str.contains(\"\\(\")) | (all_jobs.name.str.contains(\"matrix\")))]\n",
    "optimized_runs = no_fail_fast_runs[(no_fail_fast_runs.id.isin(jobs_matrix.run_id)) & (no_fail_fast_runs.conclusion==\"failure\")]\n",
    "no_fail_fast_success = no_fail_fast_runs[no_fail_fast_runs.conclusion==\"success\"]\n",
    "saved_time = []\n",
    "\n",
    "for i, row in optimized_runs.iterrows():\n",
    "    start_ts = row[\"start_ts\"]\n",
    "    success_df = no_fail_fast_success[(no_fail_fast_success.workflow_id == row[\"workflow_id\"])]\n",
    "    if success_df.shape[0] != 0:\n",
    "        success_time = success_df[(success_df.workflow_id == row[\"workflow_id\"])].up_time.to_list()[0]\n",
    "        saved_time.append(success_time - row[\"up_time\"])\n",
    "saved_time1 = sum(saved_time)/(no_fail_fast_runs.up_time.sum()+sum(saved_time))*100\n",
    "impacted_runs1 = optimized_runs.shape[0] / all_runs.shape[0]\n",
    "sum_start_ts = 0\n",
    "for i, row in no_fail_fast_runs.groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"]).reset_index().iterrows():\n",
    "    sum_start_ts += row[\"max\"] - row[\"min\"]\n",
    "sum_start_ts = sum_start_ts/(12*30*24*3600)\n",
    "save_cost1 = sum(saved_time)/sum_start_ts * 0.008 * 1.52 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddee72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"fail_fast\"]={\n",
    "    \"paid\":{\n",
    "        \"adoption\": adoption_1,\n",
    "        \"impacted_runs\": impacted_runs1*100,\n",
    "        \"time_impact\": saved_time1,\n",
    "        \"cost_impact\": save_cost1\n",
    "    },\n",
    "    \"free\":\n",
    "    {\n",
    "        \"adoption\": adoption_2,\n",
    "        \"impacted_runs\": impacted_runs2*100,\n",
    "        \"time_impact\": saved_time2,\n",
    "        \"cost_impact\": save_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb51b30-79ff-442f-a3c6-4d23183b9765",
   "metadata": {},
   "source": [
    "## Vm minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0a3261f-9faf-410e-b48a-1ff16ca6a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_minutes = get_optimization_usage_avm(collected_commits, optimization=\"timeout-minutes\")\n",
    "timeout_ = get_optimization_ts_avm(collected_commits, optimization=\"timeout-minutes:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de45d906-2610-4c32-8af7-362b3dc719df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repos = data_set.get_all_repositories()\n",
    "all_runs = data_set.get_all_runs()\n",
    "all_runs = all_runs[all_runs.repo_id.isin(repos_list_2)]\n",
    "all_jobs = data_set.get_all_jobs()\n",
    "\n",
    "all_runs[\"start_ts\"] = all_runs.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "runs_repos = all_runs.merge(all_repos, left_on=\"repo_id\", right_on=\"id\")\n",
    "\n",
    "optimized_runs_ids = []\n",
    "saved_time = []\n",
    "jobs_ids = []\n",
    "all_possible = []\n",
    "for c in timeout_:\n",
    "    candidate_runs = runs_repos[(runs_repos.full_name==c[0]) & \n",
    "            (runs_repos.workflow_file==\".github/workflows/\"+c[1]) & \n",
    "            (runs_repos.start_ts > c[2])& \n",
    "            (runs_repos.start_ts < c[3])]\n",
    "    timeout_value = c[4]\n",
    "    timed_out_jobs = all_jobs[(all_jobs.run_id.isin(candidate_runs.id_x)) & (all_jobs.up_time > timeout_value*60-59) & (all_jobs.up_time<timeout_value*60+59)]\n",
    "    max_job_time = all_jobs[all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&(runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list())].up_time.max()\n",
    "    average_high = all_jobs[(all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&\n",
    "                                                            (runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list()))&\n",
    "                           (all_jobs.up_time>timeout_value*60+30)].up_time.mean()\n",
    "    probability_high = all_jobs[(all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&\n",
    "                                                            (runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list()))&\n",
    "                           (all_jobs.up_time>timeout_value*60+30)].shape[0]/(all_jobs[(all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&\n",
    "                                                            (runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list()))].shape[0]+0.1)\n",
    "    all_possible.extend(candidate_runs.id_x.to_list())\n",
    "    if not np.isnan(average_high):\n",
    "        for i, row in timed_out_jobs.iterrows():\n",
    "            saved_time.append((average_high - timeout_value*60))\n",
    "            jobs_ids.append(row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57ff06de-a2db-4477-b03c-16f78b230044",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_vm_time2 = sum(saved_time) / (all_jobs[all_jobs.run_id.isin(all_possible)].up_time.sum()+sum(saved_time)) *100\n",
    "start_ts_min_max = runs_repos[runs_repos.id_x.isin(all_possible)].groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"])\n",
    "total_start_ts = 0\n",
    "for i, row in start_ts_min_max.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "impact_cost2 = sum(saved_time) / (total_start_ts/(12*30*24*3600)) * 1.52 * 0.008 /60\n",
    "impact_runs2 =len(all_possible)/runs_repos.shape[0]*100\n",
    "#cache_usage = get_optimization_usage(collected_commits, \"concurrency:\")\n",
    "created_with = set([(x[0],x[1]) for x in cache_usage[\"created_with_optimization\"]])\n",
    "added = set([(x[0],x[1]) for x in cache_usage[\"optimization_removed\"]])\n",
    "removed = set([(x[0],x[1]) for x in cache_usage[\"optimization_added\"]])\n",
    "len((created_with|\n",
    "    added|\n",
    "    removed))\n",
    "#cache_usage = get_optimization_usage(collected_commits, \"concurrency:\")\n",
    "created_with = set([x[0] for x in vm_minutes[\"created_with_optimization\"]])\n",
    "added = set([x[0] for x in vm_minutes[\"optimization_removed\"]])\n",
    "removed = set([x[0] for x in vm_minutes[\"optimization_added\"]])\n",
    "adoption2 = len((created_with|\n",
    "    added|\n",
    "    removed) & set(list_2_names)) / len(list_2_names) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6a50806",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repos = data_set.get_all_repositories()\n",
    "all_runs = data_set.get_all_runs()\n",
    "all_runs = all_runs[all_runs.repo_id.isin(repos_list_1)]\n",
    "all_jobs = data_set.get_all_jobs()\n",
    "\n",
    "all_runs[\"start_ts\"] = all_runs.created_at.apply(lambda x: int(time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%SZ\").timetuple())))\n",
    "runs_repos = all_runs.merge(all_repos, left_on=\"repo_id\", right_on=\"id\")\n",
    "\n",
    "optimized_runs_ids = []\n",
    "saved_time = []\n",
    "jobs_ids = []\n",
    "all_possible = []\n",
    "for c in timeout_:\n",
    "    candidate_runs = runs_repos[(runs_repos.full_name==c[0]) & \n",
    "            (runs_repos.workflow_file==\".github/workflows/\"+c[1]) & \n",
    "            (runs_repos.start_ts > c[2])& \n",
    "            (runs_repos.start_ts < c[3])]\n",
    "    timeout_value = c[4]\n",
    "    timed_out_jobs = all_jobs[(all_jobs.run_id.isin(candidate_runs.id_x)) & (all_jobs.up_time > timeout_value*60-59) & (all_jobs.up_time<timeout_value*60+59)]\n",
    "    max_job_time = all_jobs[all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&(runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list())].up_time.max()\n",
    "    average_high = all_jobs[(all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&\n",
    "                                                            (runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list()))&\n",
    "                           (all_jobs.up_time>timeout_value*60+30)].up_time.mean()\n",
    "    probability_high = all_jobs[(all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&\n",
    "                                                            (runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list()))&\n",
    "                           (all_jobs.up_time>timeout_value*60+30)].shape[0]/(all_jobs[(all_jobs.run_id.isin(runs_repos[(runs_repos.full_name==c[0])&\n",
    "                                                            (runs_repos.workflow_file==\".github/workflows/\"+c[1])].id_x.to_list()))].shape[0]+0.1)\n",
    "    all_possible.extend(candidate_runs.id_x.to_list())\n",
    "    if not np.isnan(average_high):\n",
    "        for i, row in timed_out_jobs.iterrows():\n",
    "            saved_time.append((average_high - timeout_value*60))\n",
    "            jobs_ids.append(row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1526fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_vm_time1 = sum(saved_time) / (all_jobs[all_jobs.run_id.isin(all_possible)].up_time.sum()+sum(saved_time)) *100\n",
    "start_ts_min_max = runs_repos[runs_repos.id_x.isin(all_possible)].groupby(\"repo_id\").start_ts.agg([\"min\", \"max\"])\n",
    "total_start_ts = 0\n",
    "for i, row in start_ts_min_max.iterrows():\n",
    "    total_start_ts += row[\"max\"] - row[\"min\"]\n",
    "impact_cost1 = sum(saved_time) / (total_start_ts/(12*30*24*3600)) * 1.52 * 0.008 /60\n",
    "impact_runs1 =len(all_possible)/runs_repos.shape[0]*100\n",
    "#cache_usage = get_optimization_usage(collected_commits, \"concurrency:\")\n",
    "created_with = set([(x[0],x[1]) for x in cache_usage[\"created_with_optimization\"]])\n",
    "added = set([(x[0],x[1]) for x in cache_usage[\"optimization_removed\"]])\n",
    "removed = set([(x[0],x[1]) for x in cache_usage[\"optimization_added\"]])\n",
    "len((created_with|\n",
    "    added|\n",
    "    removed))\n",
    "#cache_usage = get_optimization_usage(collected_commits, \"concurrency:\")\n",
    "created_with = set([x[0] for x in vm_minutes[\"created_with_optimization\"]])\n",
    "added = set([x[0] for x in vm_minutes[\"optimization_removed\"]])\n",
    "removed = set([x[0] for x in vm_minutes[\"optimization_added\"]])\n",
    "adoption1 = len((created_with|\n",
    "    added|\n",
    "    removed) & set(list_1_names)) / len(list_1_names) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "214bd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizations[\"custom_timeout\"]={\n",
    "    \"paid\":{\n",
    "        \"adoption\": adoption1,\n",
    "        \"impacted_runs\": impacted_runs1*100,\n",
    "        \"time_impact\": impact_vm_time1,\n",
    "        \"cost_impact\": impact_cost1\n",
    "    },\n",
    "    \"free\":\n",
    "    {\n",
    "        \"adoption\": adoption2,\n",
    "        \"impacted_runs\": impacted_runs2*100,\n",
    "        \"time_impact\": impact_vm_time2,\n",
    "        \"cost_impact\": impact_cost2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13093eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Adoption rate %          Impacted runs %          Impact on VM-time %      Annual cost delta $     \n",
      "                              ------------------------------------------------------------------------------------------------\n",
      "Conclusion                     Paid         Free         Paid         Free         Paid         Free         Paid         Free        \n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "cache                          32.9         17.8         100.0        100.0        -3.5          -6.2          -22.45        -0.61        \n",
      "fail_fast                      75.9         84.5         3.1          4.7          -1.5          -2.0          -2.13         -4.22        \n",
      "cancel_in_progress             10.1         1.9          9.2          1.7          -4.1          -1.6          -62.63        -0.52        \n",
      "skip_workflow                  9.5          4.6          0.1          0.3          -0.0          -0.4          -2.52         -0.75        \n",
      "filtering_target_files         21.1         8.7          0.1          1.8          -0.0          -0.0          -2.27         -0.06        \n",
      "custom_timeout                 14.0         2.6          3.1          4.7          -8.2          -12.9         -58.61        -1.59        \n"
     ]
    }
   ],
   "source": [
    "print(\"{:<30} {:<24} {:<24} {:<24} {:<24}\".format(\n",
    "        \"\",\n",
    "        \"Adoption rate %\",\n",
    "        \"Impacted runs %\",\n",
    "        \"Impact on VM-time %\",\n",
    "        \"Annual cost delta $\"\n",
    "         ))\n",
    "print(\" \"*30 + \"-\"*96)\n",
    "print(\"{:<30} {:<12} {:<12} {:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format(\n",
    "        \"Conclusion\",\n",
    "        \"Paid\",\n",
    "        \"Free\",\n",
    "        \"Paid\",\n",
    "        \"Free\",\n",
    "        \"Paid\",\n",
    "        \"Free\",\n",
    "        \"Paid\",\n",
    "        \"Free\"\n",
    "         ))\n",
    "print(\"-\"*126)\n",
    "for op_name in [\"cache\", \"fail_fast\", \"cancel_in_progress\", \"skip_workflow\", \"filtering_target_files\", \"custom_timeout\"]:\n",
    "    o = optimizations[op_name]\n",
    "    print(\"{:<30} {:<12} {:<12} {:<12} {:<12} -{:<12} -{:<12} -{:<12} -{:<12}\".format(\n",
    "        op_name,\n",
    "        round(o[\"paid\"][\"adoption\"], 1),\n",
    "        round(o[\"free\"][\"adoption\"], 1),\n",
    "        round(o[\"paid\"][\"impacted_runs\"], 1),\n",
    "        round(o[\"free\"][\"impacted_runs\"], 1),\n",
    "        round(o[\"paid\"][\"time_impact\"], 1),\n",
    "        round(o[\"free\"][\"time_impact\"], 1),\n",
    "        round(o[\"paid\"][\"cost_impact\"], 2),\n",
    "        round(o[\"free\"][\"cost_impact\"], 2),\n",
    "         ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
